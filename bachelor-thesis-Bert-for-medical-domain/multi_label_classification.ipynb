{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bbb647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 11:50:36.476825: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-28 11:50:36.596431: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-28 11:50:36.596449: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-28 11:50:36.619951: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-28 11:50:37.220530: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-28 11:50:37.220597: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-28 11:50:37.220605: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import datasets\n",
    "from torch.utils.data import DataLoader,Dataset,RandomSampler, SequentialSampler\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from typing import List\n",
    "from transformers import BertModel,BertTokenizer,AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import AutoModelForSequenceClassification, PreTrainedTokenizerFast\n",
    "from torch import nn ,cuda\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from transformers import BertTokenizer, BertTokenizerFast\n",
    "# cuda\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b96f7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 texts: list,\n",
    "                 labels: list,\n",
    "                 tokenizer,\n",
    "                 max_len: int,\n",
    "                 binarizer):\n",
    "        self.binarizer = binarizer\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.labels : np.ndarray =  self.binarizer.transform(labels)#np.asarray(labels)# \n",
    "        self.max_len = max_len\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item_idx):\n",
    "        text: str = self.texts[item_idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=False,\n",
    "            return_attention_mask=True,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids = inputs['input_ids'].flatten()\n",
    "        attn_mask = inputs['attention_mask'].flatten()\n",
    "\n",
    "        return {'input_ids': input_ids,\n",
    "                'attention_mask': attn_mask,\n",
    "                'label': torch.tensor(self.labels[item_idx], dtype=torch.float)\n",
    "                }\n",
    "\n",
    "\n",
    "class DataModule(pl.LightningDataModule):\n",
    "\n",
    "    ## binarizer is automatically set to None\n",
    "    ## but it must be initialized with a\n",
    "    ## binarizer, such as\n",
    "    def __init__(self, x_tr_:list, y_tr_:list,\\\n",
    "                 x_val_:list, y_val_:list,\\\n",
    "                 x_test_:list, y_test_:list,\n",
    "                 tokenizer_, batch_size=16, max_token_len=200,\n",
    "                 binarizer=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.binarizer = binarizer\n",
    "        self.tr_text = x_tr_\n",
    "        self.tr_label = y_tr_\n",
    "        self.val_text = x_val_\n",
    "        self.val_label = y_val_\n",
    "        self.test_text = x_test_\n",
    "        self.test_label = y_test_\n",
    "        self.tokenizer = tokenizer_\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = MultiLDataset(texts=self.tr_text,\n",
    "                                       labels=self.tr_label,\n",
    "                                       tokenizer=self.tokenizer, max_len=self.max_token_len, binarizer=self.binarizer)\n",
    "        self.val_dataset = MultiLDataset(texts=self.val_text, labels=self.val_label, tokenizer=self.tokenizer,\n",
    "                                     max_len=self.max_token_len, binarizer=self.binarizer)\n",
    "        self.test_dataset = MultiLDataset(texts=self.test_text, labels=self.test_label, tokenizer=self.tokenizer,\n",
    "                                      max_len=self.max_token_len, binarizer=self.binarizer)\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=16)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=16)\n",
    "\n",
    "\n",
    "# we will use the BERT base model(the smaller one)\n",
    "class LabelsClassifier(pl.LightningModule):\n",
    "    # Set up the classifier\n",
    "    def __init__(self, bert_model, n_classes:int, steps_per_epoch=None, n_epochs=3, lr=2e-5):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model, return_dict=True)\n",
    "        #self.bert = AutoModelForSequenceClassification.from_pretrained(bert_model, num_labels=n_classes,return_dict=True)\n",
    "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        self.dropout =  nn.Dropout(0.25)\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, input_ids, attn_mask):\n",
    "        output = self.bert(input_ids=input_ids, attention_mask=attn_mask)\n",
    "        print(\"first output\",  len(output.pooler_output))\n",
    "        print(\"first output 0\",  len(output.pooler_output[0]))\n",
    "        print(\"first output 1\",  len(output.pooler_output[1]))\n",
    "        print(\"output pooler\")\n",
    "        print(len(output.pooler_output[0]))\n",
    "        print(len(output.pooler_output[1]))\n",
    "        pooled_output = self.dropout(output.pooler_output)\n",
    "        print(\"after dropout \",  len(output))\n",
    "        print(\"after dropout ---  \",  len(output[0][0]))\n",
    "        print(\"after dropout ---  \",  len(output[0][1]))\n",
    "        output = self.classifier(pooled_output)\n",
    "        print(\"after linear transformation \",  output.shape)\n",
    "        print(\"output is\")\n",
    "        print(output)\n",
    "        import sys\n",
    "        sys.exit\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "\n",
    "        outputs = self(input_ids, attention_mask)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log('train_loss', loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "\n",
    "        outputs = self(input_ids, attention_mask)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log('val_loss', loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "\n",
    "        outputs = self(input_ids, attention_mask)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log('test_loss', loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.lr)\n",
    "        warmup_steps = self.steps_per_epoch // 3\n",
    "        total_steps = self.steps_per_epoch * self.n_epochs - warmup_steps\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "### move to antoher folder\n",
    "\n",
    "def _binarize(labels):\n",
    "\n",
    "    #print(MultiLabelBinarizer().fit(labels).classes_.shape)\n",
    "    return MultiLabelBinarizer().fit(labels)\n",
    "\n",
    "def split_train_test(texts:list, labels:list, random_seed=99):\n",
    "\n",
    "    x_train, x_test, y_train, y_test = \\\n",
    "            train_test_split(texts, labels,\\\n",
    "                            test_size = 0.1, random_state=random_seed,\\\n",
    "                             shuffle=True)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def func_utf8(text):\n",
    "    try:\n",
    "        return text.encode(\"latin-1\").decode(\"UTF-8\")\n",
    "    except Exception as E:\n",
    "        return  text\n",
    "\n",
    "\n",
    "def remwithre(text, there=re.compile(re.escape('Mit freundlich')+'.*')):\n",
    "    return there.sub('', text)\n",
    "\n",
    "def modelCheckpoint(filename = None, top_models = 10, mode='min'):\n",
    "    #pytorch_lightning.callbacks.ModelCheckpoint(...)\n",
    "    if(type(filename) == type(None)):\n",
    "        filename = 'Labels-{epoch:02d}-{val_loss:.2f}-{train_loss:.2f}'\n",
    "    return ModelCheckpoint(monitor = 'val_loss' ,# monitored quantity,\n",
    "                           filename=filename,\n",
    "                           save_top_k=top_models ,# save the top k models\n",
    "                           mode=mode,) # mode of the monitored quantity for optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96a2f764",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1be2fdcf59742fff\n",
      "Reusing dataset json (/home/fb198/.cache/huggingface/datasets/json/default-1be2fdcf59742fff/0.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first five rows in dataframe \n",
      "                                                 text        label_numerical  \\\n",
      "0   Fragmentiert vorliegende 0,5 cm große Probeen...  [0, 0, 1, 1, 0, 0, 0]   \n",
      "1   1 (rechts Basis medial): Eine maximal 1,3 cm ...  [0, 1, 0, 0, 1, 0, 0]   \n",
      "2  Nachbericht:  Im nachträglich eingebetteten Fe...  [0, 0, 0, 0, 1, 0, 0]   \n",
      "3   jeweils 0,5 cm durchmessende Proben vom Darm ...  [1, 0, 0, 1, 0, 0, 0]   \n",
      "4   1. Lymphknoten Milzhilus: Ein 1,6 x 1,3 x 0,5...  [1, 0, 1, 0, 0, 0, 0]   \n",
      "\n",
      "                     label  \n",
      "0  [stomach, inflammation]  \n",
      "1    [prostate, carcinoma]  \n",
      "2              [carcinoma]  \n",
      "3    [colon, inflammation]  \n",
      "4         [colon, stomach]  \n",
      "number of samples in training data 3813, number of samples in testing data 424\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## the .json file for the data is store as follow:\n",
    "##        '{\"data\":[]}'\n",
    "multi_path = \"/home/fb198/BA/classification/data_files_classification_data_multi_labeled_hf_dataset_organs_disorders.json\"\n",
    "data = datasets.Dataset.from_json(multi_path)\n",
    "data\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "#print(df.shape)\n",
    "# df.text = df['text'].apply(func_utf8)\n",
    "#for idx_, t in enumerate(texts):\n",
    "#    texts[idx_] = func_utf8(t)\n",
    "\n",
    "\n",
    "texts = [remwithre(t) for t in df.text.tolist()]\n",
    "texts = [remwithre(t,there=re.compile(re.escape('Prof.')+'.*')) for t in texts]\n",
    "texts = [t.replace(\"\\n\\r\\n\", '') for t in texts]\n",
    "texts = [t.replace(\"\\r\", '') for t in texts]\n",
    "texts = [re.sub(r'\\.+', \".\", t) for t in texts]\n",
    "texts = [re.sub(r'\\-+', \"-\", t) for t in texts]\n",
    "texts = [re.sub(r'\\,+', \"\", t) for t in texts]\n",
    "\n",
    "index2labelname = ['colon', 'prostate', 'stomach', 'inflammation', 'carcinoma', 'adenoma', 'BPH']\n",
    "labels_list = df.label.tolist()\n",
    "#labels_list[:2]\n",
    "for idx, l in enumerate(labels_list):\n",
    "    temp = []\n",
    "    for idx_, i in enumerate(l):\n",
    "        if(i == 1):\n",
    "            temp.append(index2labelname[idx_])\n",
    "    labels_list[idx] = temp\n",
    "\n",
    "df['text'] = texts\n",
    "df['label'] = labels_list\n",
    "\"\"\"\n",
    "multi_path = multi_path = \"/home/fb198/BA/DataNephroTexts/classification_data/filtered_multi_labeled_final.json\"\n",
    "data = datasets.Dataset.from_json(multi_path)\n",
    "data\n",
    "\n",
    "index2labelname = {7:'colon',\n",
    "                   1:'prostate',\n",
    "                   2:'stomach',\n",
    "                   3:'inflammation',\n",
    "                   4:'carcinoma',\n",
    "                   5:'adenoma',\n",
    "                   6:'BPH'}\n",
    "labelname2index = {'colon': 7,\n",
    "                     'prostate': 1,\n",
    "                     'stomach': 2,\n",
    "                     'inflammation': 3,\n",
    "                     'carcinoma': 4,\n",
    "                     'adenoma': 5,\n",
    "                     'BPH': 6}\n",
    "index2labelnamelist = ['colon', 'prostate', 'stomach', 'inflammation', 'carcinoma', 'adenoma', 'BPH']\n",
    "\n",
    "\n",
    "df_mulitlabel = pd.DataFrame(data)\n",
    "labels_list = df_mulitlabel.label.tolist()\n",
    "#labels_list[:2]\n",
    "for idx, l in enumerate(labels_list):\n",
    "    temp = []\n",
    "    for idx_, i in enumerate(l):\n",
    "        if(i == 1):\n",
    "            temp.append(index2labelnamelist[idx_])\n",
    "    labels_list[idx] = temp\n",
    "df_mulitlabel['labels_test'] = labels_list\n",
    "df_mulitlabel.columns = [\"text\", \"label_numerical\", \"label\"]\n",
    "print(f\"first five rows in dataframe \\n {df_mulitlabel.head(5)}\")\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = split_train_test(df_mulitlabel['text'].tolist(), df_mulitlabel['label'].tolist())\n",
    "x_tr, x_val, y_tr, y_val = split_train_test(x_train, y_train)\n",
    "print(f\"number of samples in training data {len(x_train)}, number of samples in testing data {len(x_test)}\")\n",
    "\n",
    "## binarize labels\n",
    "binarizer = _binarize(df_mulitlabel['label'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7ce4343",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/fb198/BA/nlp-in-diagnostic-texts-from-nephropathology-master/LanguageModelling/LanguageModelling/filtered_data_training_bert/sentencepiece_v1000_filtered_training_data were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at /home/fb198/BA/nlp-in-diagnostic-texts-from-nephropathology-master/LanguageModelling/LanguageModelling/filtered_data_training_bert/sentencepiece_v1000_filtered_training_data and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/fb198/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/fb198/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name       | Type              | Params\n",
      "-------------------------------------------------\n",
      "0 | bert       | BertModel         | 86.8 M\n",
      "1 | classifier | Linear            | 5.4 K \n",
      "2 | dropout    | Dropout           | 0     \n",
      "3 | criterion  | BCEWithLogitsLoss | 0     \n",
      "-------------------------------------------------\n",
      "86.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "86.8 M    Total params\n",
      "347.259   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fb198/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first output 16\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 6.7387e-03,  1.1480e-01, -1.9100e-02, -1.7665e-01,  1.3457e-01,\n",
      "          4.7156e-01, -1.2673e-01],\n",
      "        [ 5.4611e-04,  1.7378e-01,  3.8233e-02, -2.9726e-01,  1.1189e-01,\n",
      "          3.0127e-01, -1.9259e-01],\n",
      "        [ 4.9352e-04,  2.2738e-01,  4.8346e-02, -2.0077e-01,  5.1712e-02,\n",
      "          3.4578e-01, -1.7440e-01],\n",
      "        [-3.7720e-02,  1.5368e-01,  4.1026e-02, -3.2399e-01,  1.4420e-01,\n",
      "          2.7285e-01, -1.8885e-01],\n",
      "        [-1.0046e-01,  1.7977e-01, -1.2886e-01, -2.0054e-01,  1.3153e-01,\n",
      "          2.3185e-01, -2.3985e-01],\n",
      "        [ 4.2761e-02,  3.1786e-01, -4.9221e-03, -2.9027e-01,  1.2250e-01,\n",
      "          4.3284e-01, -1.6661e-01],\n",
      "        [-1.8256e-01,  1.1400e-01, -1.1158e-01, -2.9309e-01,  2.6147e-02,\n",
      "          3.7845e-01, -2.1318e-01],\n",
      "        [ 1.6019e-02,  1.4518e-01,  5.4329e-02, -3.6071e-01,  1.4061e-01,\n",
      "          3.9314e-01, -1.6631e-01],\n",
      "        [ 3.5650e-02,  2.7959e-01, -9.1225e-03, -2.5872e-01,  1.1839e-01,\n",
      "          3.9537e-01, -1.6628e-01],\n",
      "        [-4.3450e-02,  2.3936e-01, -6.2973e-02, -1.4069e-01,  3.8599e-02,\n",
      "          2.4264e-01, -2.0772e-01],\n",
      "        [ 9.2840e-03,  3.2753e-01, -5.9419e-02, -1.9275e-01,  6.3653e-02,\n",
      "          2.8184e-01, -2.3744e-01],\n",
      "        [-5.8990e-02,  8.5045e-02, -1.1909e-01, -2.2109e-01,  1.4817e-01,\n",
      "          2.0613e-01, -1.7984e-01],\n",
      "        [-3.5148e-02,  2.3482e-01, -6.1737e-02, -1.4462e-01,  4.6585e-03,\n",
      "          2.1251e-01, -2.4128e-01],\n",
      "        [-1.3879e-01,  9.9795e-02,  4.9636e-02, -4.0721e-01,  6.4091e-02,\n",
      "          3.2640e-01, -2.1737e-01],\n",
      "        [ 2.8894e-02,  1.6783e-01, -1.6331e-01, -2.8930e-01,  1.4043e-01,\n",
      "          4.8843e-01, -1.3687e-01],\n",
      "        [ 1.0646e-01,  9.6018e-02, -4.9126e-02, -3.0870e-01,  1.2444e-01,\n",
      "          5.4957e-01, -1.0726e-01]], device='cuda:0')\n",
      "first output 16\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.1605,  0.1411,  0.0808, -0.2139,  0.0200,  0.3585, -0.1784],\n",
      "        [-0.1113,  0.1086, -0.1183, -0.2367, -0.0782,  0.3973, -0.1937],\n",
      "        [-0.1196,  0.1530,  0.0116, -0.1095,  0.0023,  0.3769, -0.2881],\n",
      "        [ 0.0325,  0.1729, -0.0340, -0.3556,  0.0316,  0.3235, -0.0905],\n",
      "        [-0.0254,  0.1440,  0.0474, -0.2589,  0.0615,  0.2622, -0.2067],\n",
      "        [-0.0094,  0.1635, -0.1619, -0.0904,  0.0641,  0.2931, -0.1917],\n",
      "        [-0.0689,  0.1768,  0.0222, -0.1889,  0.0136,  0.2516, -0.2085],\n",
      "        [ 0.0180,  0.1745, -0.0878, -0.1062,  0.1035,  0.2602, -0.2531],\n",
      "        [-0.0922,  0.1345, -0.1116, -0.2990,  0.0414,  0.4632, -0.2572],\n",
      "        [-0.1323,  0.2736,  0.0097, -0.3197, -0.0212,  0.6928, -0.3612],\n",
      "        [-0.2726,  0.1066,  0.0525, -0.2901, -0.1419,  0.4420, -0.2433],\n",
      "        [-0.0613,  0.1072,  0.0218, -0.3144,  0.0868,  0.3134, -0.1677],\n",
      "        [-0.2022,  0.2553, -0.0405, -0.1731, -0.0211,  0.3266, -0.3570],\n",
      "        [-0.0195,  0.1853, -0.1321, -0.2138,  0.0348,  0.3634, -0.1078],\n",
      "        [-0.0050,  0.2815, -0.0784, -0.1218,  0.0857,  0.2914, -0.1974],\n",
      "        [ 0.0346,  0.2095, -0.0489, -0.2967,  0.0404,  0.3137, -0.1425]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a308e177fe474388a1f55ceb89c84d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[-6.6036e-02,  1.4730e-01,  1.6796e-01, -3.6946e-01, -1.7041e-01,\n",
      "          3.3733e-01, -2.6364e-01],\n",
      "        [-6.0434e-02,  3.5377e-01,  5.8967e-02, -9.3585e-02,  4.6960e-02,\n",
      "          5.3334e-01, -3.0478e-01],\n",
      "        [ 1.4390e-01,  1.4911e-01,  3.8628e-02, -2.5260e-02, -1.0178e-02,\n",
      "          3.6828e-01, -7.9918e-02],\n",
      "        [ 1.9890e-01, -5.9780e-02, -3.0142e-01,  5.7307e-04,  6.8347e-02,\n",
      "          4.3350e-01, -1.8661e-01],\n",
      "        [-1.0477e-01,  3.8868e-01, -2.7279e-01, -4.4215e-01,  3.8445e-01,\n",
      "          2.3266e-01, -3.8824e-02],\n",
      "        [-1.4314e-01,  1.2277e-01,  1.3839e-01, -1.2012e-01, -4.6299e-02,\n",
      "          5.7934e-02, -6.3797e-01],\n",
      "        [-1.2871e-01,  1.2971e-01, -4.3321e-01, -4.4223e-01,  1.6150e-01,\n",
      "          2.4308e-01,  2.2294e-02],\n",
      "        [-7.1896e-02,  2.8708e-01,  1.7436e-01, -4.9389e-01,  2.1435e-01,\n",
      "          4.1698e-01, -4.0217e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[-0.0179,  0.4739,  0.2264, -0.0300,  0.3700,  0.2672, -0.0353],\n",
      "        [-0.0956,  0.3993, -0.1042, -0.3009,  0.1830,  0.0388,  0.1232],\n",
      "        [-0.0677,  0.1714, -0.0209, -0.1342, -0.0532,  0.3949, -0.0563],\n",
      "        [-0.0639, -0.1172, -0.2129, -0.3521, -0.0782,  0.1469,  0.0206],\n",
      "        [-0.2504,  0.2420,  0.2615, -0.1271,  0.1349,  0.2886, -0.5001],\n",
      "        [-0.2590,  0.0266,  0.0436, -0.2926,  0.4348,  0.2415, -0.1664],\n",
      "        [-0.1936,  0.1158,  0.1525, -0.4277, -0.1080,  0.4825, -0.4860],\n",
      "        [ 0.0461,  0.3532, -0.1613, -0.3133,  0.0658,  0.4616, -0.0416]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[ 0.2002,  0.3787, -0.1876, -0.1362, -0.0398,  0.2079, -0.2977],\n",
      "        [ 0.1813,  0.1172,  0.1778, -0.2738,  0.1481,  0.6143, -0.0110],\n",
      "        [-0.3791,  0.1937,  0.2275, -0.4529, -0.0317,  0.2655, -0.3076],\n",
      "        [-0.0944,  0.1546,  0.2580, -0.0971, -0.0802,  0.4906, -0.2678],\n",
      "        [ 0.1539,  0.3061, -0.0855,  0.0075, -0.0523,  0.5884, -0.3868],\n",
      "        [ 0.1837,  0.1589,  0.0499, -0.0051,  0.5973,  0.4612, -0.1113],\n",
      "        [ 0.2103,  0.3139,  0.0911, -0.2806, -0.2853,  0.0729, -0.3101],\n",
      "        [-0.0903,  0.1621,  0.1681, -0.1565,  0.3355,  0.0878, -0.2405]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[ 0.0868,  0.3001, -0.0472, -0.0513,  0.1086,  0.3310, -0.2708],\n",
      "        [ 0.1670,  0.0031,  0.0082, -0.3202,  0.3748,  0.3153,  0.2979],\n",
      "        [-0.1404,  0.1367, -0.1824, -0.0238, -0.0515,  0.2817, -0.3886],\n",
      "        [-0.0193,  0.3034, -0.2156, -0.4158,  0.2760,  0.2392, -0.0581],\n",
      "        [ 0.1617,  0.2594, -0.0161,  0.1145,  0.2233,  0.3399, -0.3236],\n",
      "        [-0.1164,  0.3467, -0.3234, -0.3443,  0.4500,  0.1699, -0.1354],\n",
      "        [-0.1581, -0.0370,  0.0337, -0.3630,  0.2375,  0.3402,  0.1178],\n",
      "        [ 0.2688, -0.2350, -0.4278, -0.3111, -0.1350,  0.2926, -0.0696]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[-0.1823,  0.2053, -0.2775, -0.2888,  0.2540,  0.0988, -0.3646],\n",
      "        [ 0.0262,  0.2651, -0.1445, -0.3432,  0.0556,  0.4323, -0.3425],\n",
      "        [-0.1945,  0.2959, -0.3444, -0.0486,  0.0340,  0.4796, -0.0272],\n",
      "        [ 0.0372,  0.1240, -0.0374, -0.5732, -0.0520,  0.1470, -0.1269],\n",
      "        [-0.1450,  0.2385,  0.1034,  0.1055, -0.1721,  0.2529, -0.2735],\n",
      "        [-0.0057,  0.2260, -0.1499, -0.2421, -0.1184,  0.6183, -0.2684],\n",
      "        [-0.1744, -0.0644,  0.1373, -0.2291, -0.1153,  0.0198, -0.1368],\n",
      "        [-0.2011, -0.1047, -0.0497, -0.1565,  0.2639,  0.5894, -0.1948]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[ 5.0136e-02,  1.1689e-02, -2.4536e-01, -3.1632e-01, -2.5839e-01,\n",
      "          2.7858e-01, -3.2485e-01],\n",
      "        [-2.9639e-01,  8.5677e-02,  2.2156e-01, -3.8799e-01,  1.1051e-01,\n",
      "         -5.7572e-02, -1.9099e-02],\n",
      "        [-3.6672e-02, -3.8049e-02, -2.9115e-01, -3.1185e-01, -1.2554e-01,\n",
      "          4.0916e-01, -2.1915e-01],\n",
      "        [ 9.5097e-02,  5.5943e-01, -2.5311e-01, -1.7686e-01, -6.5590e-02,\n",
      "          5.4775e-01, -1.1001e-01],\n",
      "        [ 2.2078e-01,  5.4293e-02,  2.2644e-01, -4.9946e-02,  1.4941e-01,\n",
      "          1.1540e-01, -2.0427e-01],\n",
      "        [-5.4967e-02,  2.1739e-01, -3.4531e-02, -2.3203e-04,  4.0586e-02,\n",
      "          8.0718e-01, -5.6679e-01],\n",
      "        [ 1.5402e-01,  2.8199e-01, -7.2696e-02, -7.3111e-02,  3.6169e-01,\n",
      "          3.5382e-01, -2.9416e-01],\n",
      "        [-5.1040e-02,  3.4038e-01, -3.5168e-02, -2.9746e-01,  9.4544e-02,\n",
      "          3.5854e-01, -3.2624e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[ 0.1437, -0.0985,  0.4086, -0.0685,  0.2025,  0.3578, -0.3539],\n",
      "        [ 0.0941,  0.4204, -0.1282, -0.4507,  0.1627,  0.0544, -0.1203],\n",
      "        [-0.0631,  0.1395, -0.0543, -0.2245, -0.1740,  0.5883, -0.3219],\n",
      "        [-0.0982, -0.0288, -0.2509, -0.1786,  0.0203,  0.3152,  0.0253],\n",
      "        [-0.0438, -0.0091, -0.1340, -0.3246, -0.1947, -0.2570, -0.3076],\n",
      "        [-0.1079, -0.1226, -0.1313, -0.2796,  0.0218,  0.2430, -0.3186],\n",
      "        [ 0.0302,  0.3618,  0.0685, -0.3138, -0.0357,  0.4154, -0.0119],\n",
      "        [ 0.3732,  0.2210,  0.0627, -0.1370, -0.1002,  0.2610, -0.0557]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[-0.1764, -0.0914,  0.1290, -0.5431,  0.1780,  0.4062, -0.5051],\n",
      "        [ 0.2353,  0.0692, -0.0927, -0.2214,  0.1995,  0.4600,  0.0840],\n",
      "        [ 0.1179,  0.0512,  0.0300, -0.3241,  0.2599,  0.3754,  0.3275],\n",
      "        [-0.1495,  0.2426, -0.1482, -0.0327, -0.0874,  0.2988, -0.1045],\n",
      "        [ 0.0268,  0.0943,  0.4819,  0.1280, -0.1985,  0.2116, -0.4261],\n",
      "        [ 0.1468,  0.3818,  0.0951, -0.3336,  0.2640,  0.4377, -0.0825],\n",
      "        [-0.0220,  0.0031, -0.0464, -0.2064,  0.2318,  0.1724, -0.0837],\n",
      "        [ 0.2157,  0.1268, -0.1100,  0.0364,  0.1054,  0.4289, -0.2761]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[ 0.0310,  0.5032, -0.0970, -0.2175, -0.1381,  0.0829,  0.0782],\n",
      "        [-0.0398,  0.1543,  0.2319, -0.0936,  0.1732,  0.1937, -0.2723],\n",
      "        [-0.3464,  0.0790, -0.1107, -0.5117,  0.0387,  0.8389,  0.0736],\n",
      "        [ 0.1416,  0.2867,  0.0637,  0.0392, -0.0861,  0.1166, -0.1860],\n",
      "        [-0.1506,  0.1386,  0.2109, -0.3218,  0.0980,  0.7958, -0.0432],\n",
      "        [ 0.0234,  0.5302, -0.2681, -0.2902, -0.0368,  0.6210, -0.1478],\n",
      "        [-0.5369, -0.0127, -0.3511,  0.2152, -0.1687,  0.5329, -0.4045],\n",
      "        [-0.2835,  0.2277, -0.3892, -0.0887,  0.0804, -0.0453, -0.2014]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[ 0.0165,  0.2549,  0.1174, -0.2102,  0.0383,  0.3717, -0.3256],\n",
      "        [-0.1990,  0.3969,  0.0468, -0.0386,  0.2274,  0.2332, -0.3635],\n",
      "        [ 0.1784,  0.2020,  0.0620, -0.4085,  0.2202,  0.4033, -0.4628],\n",
      "        [-0.3551, -0.1064, -0.0679,  0.0690,  0.3388,  0.2311, -0.5528],\n",
      "        [ 0.1842,  0.3570, -0.1102, -0.2578,  0.1848,  0.1203, -0.4006],\n",
      "        [ 0.0410, -0.1860, -0.2038, -0.4420,  0.4830,  0.3549, -0.0340],\n",
      "        [ 0.0595,  0.1466, -0.0529, -0.3266, -0.1165,  0.2789, -0.3706],\n",
      "        [ 0.0608,  0.2461,  0.1387,  0.0366, -0.0184,  0.3901, -0.0720]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[-0.0358,  0.3793, -0.0983, -0.1546,  0.0202,  0.1003, -0.0816],\n",
      "        [ 0.0523,  0.0594, -0.0445, -0.1242,  0.2898,  0.1820,  0.0234],\n",
      "        [ 0.1373,  0.4650,  0.2107, -0.2329, -0.0410,  0.3732, -0.1362],\n",
      "        [-0.1654,  0.1601, -0.1185,  0.0620,  0.2454,  0.1995, -0.3499],\n",
      "        [-0.2032,  0.0331,  0.0283, -0.4142,  0.0070,  0.0079, -0.4267],\n",
      "        [-0.1794,  0.0869, -0.1020, -0.2630,  0.1302,  0.4758,  0.0284],\n",
      "        [-0.1332,  0.0606, -0.0393, -0.1680,  0.1264,  0.4026, -0.1387],\n",
      "        [-0.3717,  0.3998, -0.2215, -0.2732,  0.0085,  0.1385, -0.4418]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[-0.1535,  0.1513, -0.0202, -0.2774,  0.2119,  0.0640, -0.2818],\n",
      "        [-0.0707,  0.1633, -0.2810, -0.3002,  0.0036,  0.1651, -0.0160],\n",
      "        [ 0.3079,  0.0252,  0.0858, -0.6248, -0.0026,  0.5150, -0.1965],\n",
      "        [-0.0358,  0.0435, -0.4988, -0.2575,  0.2844,  0.1506, -0.2469],\n",
      "        [-0.1255,  0.2699, -0.0351, -0.0617,  0.0983, -0.0797, -0.4386],\n",
      "        [ 0.0787,  0.0597,  0.1869, -0.2465,  0.3646,  0.3996, -0.1876],\n",
      "        [ 0.1261,  0.1345,  0.0221, -0.0770,  0.1617,  0.3911, -0.1828],\n",
      "        [ 0.0183, -0.0609, -0.0172, -0.5441,  0.1224,  0.3519, -0.2266]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[-0.4237,  0.1491, -0.0151, -0.2146,  0.0860,  0.4057, -0.0218],\n",
      "        [-0.1735,  0.1799,  0.2542, -0.1861,  0.1336,  0.4614, -0.0403],\n",
      "        [ 0.2222,  0.1927,  0.0546, -0.1856,  0.1150,  0.3393, -0.2128],\n",
      "        [-0.0333,  0.2116,  0.0020, -0.1481,  0.0034,  0.2024, -0.2789],\n",
      "        [-0.4460,  0.0553,  0.0560, -0.3378, -0.1996,  0.4106, -0.1318],\n",
      "        [ 0.0286,  0.1096,  0.1396, -0.3339, -0.0218, -0.1678, -0.5309],\n",
      "        [-0.1700, -0.0025,  0.0568, -0.3705,  0.0949,  0.2607, -0.2119],\n",
      "        [ 0.0694,  0.5097, -0.1337, -0.4279, -0.0396,  0.6092, -0.2983]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[-0.2379,  0.1332,  0.0020, -0.2907,  0.1175,  0.3727, -0.5509],\n",
      "        [-0.1406,  0.3172, -0.2660, -0.3103,  0.1680,  0.3082, -0.0297],\n",
      "        [-0.4743, -0.1062, -0.0408, -0.0278, -0.0086,  0.3644, -0.2733],\n",
      "        [ 0.0851,  0.4446, -0.1074, -0.1987,  0.1435,  0.4089, -0.3611],\n",
      "        [-0.4286, -0.1307,  0.4129, -0.5454,  0.3386,  0.2548, -0.3955],\n",
      "        [-0.0117, -0.1252,  0.1365, -0.3864, -0.0451,  0.2053, -0.0831],\n",
      "        [-0.0647,  0.2769, -0.0597, -0.2452,  0.0789,  0.2155,  0.1881],\n",
      "        [ 0.1839,  0.0945, -0.3398, -0.2254, -0.2255,  0.5747, -0.2128]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[-0.3263,  0.4154, -0.1388, -0.0919,  0.0629,  0.3061, -0.2801],\n",
      "        [-0.1278,  0.1595, -0.0206, -0.4294,  0.1346,  0.3698, -0.1427],\n",
      "        [ 0.1533,  0.0573,  0.1035, -0.4472, -0.0522,  0.3397, -0.0937],\n",
      "        [-0.1779,  0.2723, -0.0156, -0.1852, -0.1567,  0.4566, -0.3515],\n",
      "        [-0.0011,  0.2707,  0.0523,  0.0944,  0.1294,  0.3376, -0.1321],\n",
      "        [ 0.0878,  0.0096, -0.0335, -0.0880,  0.2524,  0.2566, -0.2504],\n",
      "        [ 0.2380,  0.3396, -0.2257, -0.0273,  0.0848,  0.2064, -0.2489],\n",
      "        [-0.2264,  0.4136,  0.0343, -0.0051, -0.1081,  0.2637, -0.0788]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[-0.1166,  0.4831, -0.0811, -0.2020, -0.0586,  0.4549, -0.1785],\n",
      "        [ 0.1993,  0.1381, -0.1149, -0.3175,  0.3317,  0.4756, -0.3244],\n",
      "        [ 0.0556,  0.0148,  0.1069, -0.0579,  0.2272, -0.0043, -0.2497],\n",
      "        [-0.1998,  0.2217,  0.0076, -0.0389, -0.1114,  0.6375, -0.2876],\n",
      "        [-0.0083,  0.0401,  0.1359, -0.2388,  0.2288,  0.4360, -0.4590],\n",
      "        [-0.2901,  0.1181, -0.2900, -0.1004,  0.4278,  0.2686,  0.0518],\n",
      "        [ 0.0205, -0.1321,  0.1143, -0.1898,  0.1474,  0.3111, -0.4651],\n",
      "        [-0.2543, -0.0015,  0.3078, -0.0981, -0.0777,  0.3808, -0.3688]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[ 0.2582, -0.1873, -0.0842, -0.1411,  0.1592,  0.1005,  0.1842],\n",
      "        [ 0.1115,  0.1259,  0.1159, -0.3485,  0.2859,  0.3326,  0.1158],\n",
      "        [-0.0041,  0.4529, -0.1368, -0.4980, -0.3192,  0.3021, -0.2455],\n",
      "        [-0.2454,  0.0794, -0.3936, -0.2997, -0.2064,  0.4243, -0.4070],\n",
      "        [-0.0399,  0.3208, -0.0150, -0.3226,  0.0892,  0.2492, -0.0973],\n",
      "        [ 0.1388,  0.1295, -0.3115, -0.3943, -0.1140,  0.4237, -0.1872],\n",
      "        [-0.2492, -0.0313,  0.0745, -0.2270, -0.0174,  0.4312, -0.0353],\n",
      "        [ 0.3421, -0.0669, -0.1435, -0.1735,  0.2750,  0.2406, -0.1501]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[ 0.0807,  0.1725,  0.0559, -0.0250,  0.0072,  0.3280, -0.1529],\n",
      "        [-0.4429, -0.2299, -0.1216, -0.0055,  0.3759,  0.2649, -0.1797],\n",
      "        [-0.1156,  0.5487,  0.0767, -0.2225,  0.0420,  0.2199, -0.3296],\n",
      "        [ 0.0485,  0.1376, -0.0544, -0.2117,  0.1621,  0.0191, -0.4527],\n",
      "        [-0.2067,  0.1692, -0.0356, -0.1579, -0.1239,  0.0507, -0.3592],\n",
      "        [-0.0429,  0.1460,  0.1714, -0.2120,  0.2069,  0.3947, -0.1636],\n",
      "        [ 0.1711,  0.4946,  0.1624, -0.3174, -0.0242,  0.4777, -0.3368],\n",
      "        [-0.2310,  0.4772, -0.2367,  0.1959,  0.0016,  0.2018, -0.3311]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[ 0.1998, -0.0340,  0.1166,  0.1042,  0.0360,  0.2208, -0.3306],\n",
      "        [ 0.0378, -0.1835, -0.0943, -0.2911,  0.1807,  0.3315,  0.0857],\n",
      "        [ 0.0999,  0.3059,  0.0187, -0.1486,  0.2664,  0.2839, -0.2769],\n",
      "        [ 0.0552,  0.3255,  0.1112, -0.2846, -0.2466, -0.0445, -0.2265],\n",
      "        [ 0.0227, -0.1901,  0.2537, -0.0518, -0.0637,  0.4876, -0.1751],\n",
      "        [-0.1540, -0.1029,  0.1340, -0.4167, -0.3214,  0.6383, -0.0736],\n",
      "        [ 0.2376,  0.2049, -0.4304,  0.0502,  0.1528,  0.3734,  0.0592],\n",
      "        [-0.0920,  0.2091, -0.0658,  0.0077,  0.2018,  0.1111,  0.1494]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[ 0.0036,  0.1917,  0.0972, -0.1857,  0.2575,  0.3651, -0.3480],\n",
      "        [-0.0184,  0.1981, -0.2919, -0.3368,  0.0175,  0.5121,  0.0628],\n",
      "        [-0.3149,  0.0673, -0.1895, -0.2725, -0.1782,  0.1070, -0.0745],\n",
      "        [-0.0606,  0.2068,  0.0940, -0.0503, -0.1350,  0.1191, -0.3578],\n",
      "        [ 0.0286, -0.1122,  0.0285, -0.4581,  0.0430,  0.1871, -0.2131],\n",
      "        [-0.0251,  0.0040,  0.0432, -0.1725,  0.1879,  0.6077, -0.0340],\n",
      "        [ 0.1549, -0.0857,  0.0565, -0.2180,  0.5951,  0.1601, -0.1295],\n",
      "        [ 0.0855,  0.1161, -0.2419,  0.0777,  0.0580,  0.1688, -0.1367]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[-0.1140, -0.0828, -0.1512,  0.0390, -0.1512,  0.4426, -0.3996],\n",
      "        [ 0.1214,  0.2349, -0.0654, -0.2530, -0.2431,  0.4939, -0.4786],\n",
      "        [-0.1876,  0.1381,  0.1686, -0.3227, -0.5041,  0.1714, -0.3658],\n",
      "        [-0.4779,  0.0402, -0.0206, -0.0316,  0.3579,  0.2470, -0.1463],\n",
      "        [-0.2120,  0.3105,  0.0481, -0.1038, -0.0033,  0.2513, -0.1640],\n",
      "        [-0.0130,  0.1014, -0.0945, -0.2194,  0.1614,  0.3077, -0.2326],\n",
      "        [ 0.0021,  0.0685, -0.1552, -0.3045, -0.0585,  0.2771,  0.2439],\n",
      "        [-0.0067,  0.2813, -0.0636, -0.3171,  0.0935,  0.3315, -0.4027]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[ 0.0159,  0.1056, -0.2486, -0.3589, -0.2804,  0.1100,  0.3595],\n",
      "        [-0.0901,  0.2141, -0.0955, -0.5069,  0.1316,  0.4943, -0.1100],\n",
      "        [-0.3361,  0.2709, -0.2517, -0.3527, -0.1949, -0.1022, -0.6530],\n",
      "        [ 0.2907,  0.2270, -0.1880, -0.0916, -0.0568,  0.3619, -0.1697],\n",
      "        [-0.0165,  0.3319,  0.0737, -0.4044,  0.0697,  0.5271, -0.1253],\n",
      "        [ 0.1479, -0.0014,  0.0164, -0.2687,  0.0862,  0.3508,  0.0050],\n",
      "        [ 0.0102,  0.1622, -0.0748, -0.0264,  0.1136,  0.3427, -0.1375],\n",
      "        [ 0.0066,  0.1970,  0.1033, -0.3233, -0.2618,  0.4094, -0.0255]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[-0.2823,  0.1238,  0.0762, -0.1879,  0.0520,  0.2947, -0.3374],\n",
      "        [-0.1522,  0.2740,  0.2118, -0.1963,  0.0071,  0.4499, -0.3051],\n",
      "        [-0.1827,  0.0347,  0.1130, -0.1342,  0.0833,  0.2724, -0.0304],\n",
      "        [-0.0572, -0.1074,  0.1110, -0.1682,  0.1339,  0.3653, -0.2107],\n",
      "        [ 0.3784,  0.0344,  0.2147, -0.5907, -0.0627,  0.2644, -0.2646],\n",
      "        [ 0.0377,  0.5116,  0.0063, -0.2606,  0.1864,  0.4014, -0.0016],\n",
      "        [ 0.0857,  0.0287,  0.2591, -0.2000,  0.1717,  0.2397,  0.0530],\n",
      "        [ 0.1383, -0.0380, -0.0690, -0.1629,  0.0517,  0.4825, -0.4396]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[ 0.0339,  0.5383, -0.2213, -0.1254, -0.0965,  0.1962, -0.1902],\n",
      "        [ 0.2554,  0.2586,  0.2914, -0.1755,  0.0719,  0.6368, -0.3144],\n",
      "        [ 0.2305,  0.4009,  0.0394, -0.4164, -0.0459,  0.3525, -0.2973],\n",
      "        [ 0.0660,  0.4864,  0.0620,  0.0151,  0.1586,  0.1295, -0.0579],\n",
      "        [ 0.1090,  0.4896, -0.3202, -0.3606,  0.0654,  0.1549, -0.1284],\n",
      "        [ 0.1824,  0.0712, -0.0353, -0.2112, -0.0481,  0.1818, -0.5180],\n",
      "        [ 0.1764,  0.1003, -0.0402,  0.0372,  0.1974,  0.2906, -0.0780],\n",
      "        [-0.0143,  0.4238, -0.0965, -0.6618,  0.1827,  0.1601, -0.2136]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "first output 8\n",
      "first output 0 768\n",
      "first output 1 768\n",
      "output pooler\n",
      "768\n",
      "768\n",
      "after dropout  2\n",
      "after dropout ---   512\n",
      "after dropout ---   512\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[ 0.0278,  0.1072, -0.0740, -0.0371, -0.0182,  0.0524, -0.4372],\n",
      "        [-0.0943, -0.2524,  0.1392, -0.3656,  0.2896,  0.5082, -0.2072],\n",
      "        [-0.2196,  0.1419,  0.0493, -0.3005, -0.3263,  0.1179, -0.4517],\n",
      "        [ 0.0719,  0.0395, -0.0354, -0.4803,  0.4006,  0.5395, -0.2524],\n",
      "        [ 0.5374,  0.3006, -0.1095, -0.3973,  0.0549,  0.4628,  0.3863],\n",
      "        [-0.1008,  0.1063,  0.0390, -0.2436, -0.4251,  0.3113, -0.2350],\n",
      "        [-0.0532,  0.0293,  0.1305, -0.2428,  0.2820,  0.1259, -0.4883],\n",
      "        [-0.1229,  0.1169,  0.0724, -0.0833, -0.0085,  0.5006, -0.4356]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fb198/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "## tokenizer's path\n",
    "\n",
    "#model_tk_path = \"/home/fb198/BA/nlp-in-diagnostic-texts-from-nephropathology-master/LanguageModelling/LanguageModelling/mlm_evaluation_2/bert-1_sp_1_batch_size_8\"\n",
    "#tk_filtered = \"/home/fb198/BA/nlp-in-diagnostic-texts-from-nephropathology-master/LanguageModelling/LanguageModelling/mlm_evaluation_2/bert-1_sp_1_batch_size_8\"\n",
    "pretrained_model_pth = \"/home/fb198/BA/nlp-in-diagnostic-texts-from-nephropathology-master/LanguageModelling/LanguageModelling/filtered_data_training_bert/sentencepiece_v1000_filtered_training_data\"\n",
    "BERT_MODEL_NAME = pretrained_model_pth\n",
    "\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(BERT_MODEL_NAME)\n",
    "#tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 8\n",
    "data_module = DataModule(x_tr_ = x_tr ,y_tr_ = y_tr,\n",
    "                            x_val_ = x_val, y_val_ = y_val,\n",
    "                            x_test_ = x_test, y_test_=y_test,\n",
    "                            tokenizer_ = tokenizer,\n",
    "                            batch_size=BATCH_SIZE, max_token_len=MAX_LEN, binarizer=binarizer)\n",
    "data_module.setup()\n",
    "checkpoint_callback = modelCheckpoint()\n",
    "num_unique_classes =  len(binarizer.classes_) #len(df_mulitlabel.label.tolist()[0]) ## adjust it to a\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE_ = 8 \n",
    "LR = 2e-05\n",
    "steps_per_epoch = len(x_tr)//BATCH_SIZE_\n",
    "\n",
    "\n",
    "model = LabelsClassifier(BERT_MODEL_NAME,\n",
    "                    n_classes=num_unique_classes,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    n_epochs=N_EPOCHS,\n",
    "                    lr=LR\n",
    "                        )\n",
    "\n",
    "# Instantiate and set up the data_module\n",
    "\n",
    "model\n",
    "# Instantiate the Model Trainer\n",
    "trainer = pl.Trainer(max_epochs=N_EPOCHS, gpus=1, callbacks=[checkpoint_callback], enable_progress_bar=True)\n",
    "# Train the Classifier Model\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0eba1f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6931471805599453"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,0,0]).dot(np.log([0.5,0.1,0.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7756e6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.3025850929940455"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0,1,0]).dot(np.log([0.8,0.1,0.1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dd44bc",
   "metadata": {},
   "source": [
    "# test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bea59334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fb198/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb58a18d42994ef39004aa95e19052ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 3.1158e-01, -4.5311e-01, -5.6874e-02, -1.8313e-01, -3.6651e-01,\n",
      "          9.0005e-02,  8.5200e-02],\n",
      "        [ 1.4309e-01, -2.6659e-01, -2.6319e-01, -2.4824e-01, -3.1615e-01,\n",
      "          8.7576e-02,  1.0758e-01],\n",
      "        [ 2.9626e-01, -2.0970e-01, -2.5891e-01, -2.1066e-01, -2.7369e-01,\n",
      "          2.1883e-01,  7.1913e-02],\n",
      "        [ 3.0371e-01, -2.9100e-02, -1.1777e-01, -9.2428e-02, -2.9317e-01,\n",
      "          2.4454e-01,  2.1991e-01],\n",
      "        [ 2.9084e-01, -1.6524e-01, -1.5787e-01, -1.7299e-01, -2.8365e-01,\n",
      "          5.8818e-02,  1.1024e-01],\n",
      "        [ 1.7204e-01, -3.3301e-01, -2.4086e-01, -1.1848e-01, -4.6661e-01,\n",
      "          7.9397e-02,  2.2292e-01],\n",
      "        [ 1.4905e-01, -1.7121e-01, -4.1588e-02, -2.0829e-01, -2.2960e-01,\n",
      "          1.9639e-01,  2.3637e-01],\n",
      "        [ 3.7817e-01, -3.6942e-01, -2.1609e-01, -1.9435e-01, -2.5473e-01,\n",
      "         -5.3759e-02,  2.1029e-01],\n",
      "        [ 2.8788e-01, -2.5996e-01, -7.0606e-02,  1.3954e-02, -4.7480e-01,\n",
      "          2.2793e-01, -6.4274e-02],\n",
      "        [ 2.6124e-01,  1.0243e-01, -8.4469e-02, -1.4895e-01, -4.9242e-01,\n",
      "          3.2770e-02,  1.4879e-01],\n",
      "        [ 2.6409e-01, -1.8229e-01, -1.5574e-01, -1.4837e-01, -3.2644e-01,\n",
      "          1.9835e-02,  3.3041e-03],\n",
      "        [ 1.4164e-01, -5.3263e-02, -9.7363e-02, -2.6867e-01, -3.9766e-01,\n",
      "          1.9010e-01,  1.3767e-02],\n",
      "        [ 3.6673e-01, -2.0680e-01, -1.5068e-01, -1.6696e-01, -3.8718e-01,\n",
      "          7.1496e-02,  1.1799e-01],\n",
      "        [ 3.3098e-01,  6.3786e-02, -1.3369e-01, -4.6088e-02, -2.8019e-01,\n",
      "          1.0008e-01,  6.4498e-02],\n",
      "        [ 1.8026e-01, -3.2609e-01, -2.1162e-01, -9.8608e-02, -4.6425e-01,\n",
      "          7.5965e-02,  2.3757e-01],\n",
      "        [ 2.6027e-01, -2.2521e-01, -2.2460e-01, -2.2044e-01, -3.1600e-01,\n",
      "         -3.1164e-04,  1.7380e-01]], device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.2908, -0.2356, -0.0982, -0.2183, -0.1783,  0.1068,  0.1380],\n",
      "        [ 0.1234, -0.2279, -0.1776, -0.1406, -0.1729,  0.0960,  0.2276],\n",
      "        [ 0.3195, -0.1465, -0.1988, -0.0347, -0.2604, -0.0948,  0.0534],\n",
      "        [ 0.2576,  0.0342, -0.0110, -0.1900, -0.3334, -0.0045,  0.0905],\n",
      "        [ 0.1299, -0.2262, -0.0520, -0.2116, -0.4119,  0.2569,  0.1964],\n",
      "        [ 0.2663, -0.1830, -0.0968, -0.1739, -0.2173,  0.1557,  0.1340],\n",
      "        [ 0.3856, -0.1440, -0.1274, -0.1376, -0.2479, -0.0413,  0.0729],\n",
      "        [ 0.2216, -0.0747, -0.1473, -0.2815, -0.3178,  0.1285,  0.0409],\n",
      "        [ 0.4240, -0.1546, -0.2132, -0.1610, -0.3523,  0.0108, -0.0126],\n",
      "        [ 0.2477, -0.2809, -0.1294, -0.1551, -0.3230,  0.0965,  0.0468],\n",
      "        [ 0.3957, -0.0679, -0.0856, -0.0943, -0.2800,  0.0706,  0.0306],\n",
      "        [ 0.2844, -0.0762, -0.0994, -0.1740, -0.3645,  0.1330, -0.1107],\n",
      "        [ 0.2510, -0.2402, -0.1825, -0.1863, -0.3399,  0.0132,  0.1190],\n",
      "        [ 0.2742, -0.1928, -0.0803, -0.1286, -0.2595,  0.0153,  0.1509],\n",
      "        [ 0.1936, -0.1023, -0.1353, -0.3654, -0.3803,  0.1765,  0.0966],\n",
      "        [ 0.3450, -0.2049, -0.1414, -0.0686, -0.3298,  0.0126, -0.0046]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.1969, -0.1486, -0.1891, -0.2881, -0.3183,  0.1356,  0.0898],\n",
      "        [ 0.2981, -0.1800, -0.0576, -0.2308, -0.2791,  0.1722,  0.0471],\n",
      "        [ 0.2451, -0.2160, -0.0397, -0.2105, -0.3242,  0.1422,  0.0805],\n",
      "        [ 0.2213, -0.0951, -0.1517, -0.1450, -0.2367,  0.0550,  0.0601],\n",
      "        [ 0.2097, -0.2216, -0.2057, -0.1077, -0.2845,  0.1428,  0.2416],\n",
      "        [ 0.1615,  0.0788, -0.2629, -0.0942, -0.3123,  0.0214,  0.2381],\n",
      "        [ 0.1167,  0.0071, -0.0779, -0.1534, -0.3407,  0.2798,  0.1826],\n",
      "        [ 0.2215, -0.0823, -0.0511, -0.1507, -0.2767,  0.0869,  0.1262],\n",
      "        [ 0.2538, -0.3060, -0.1718, -0.2267, -0.1844,  0.0227,  0.2867],\n",
      "        [ 0.2931, -0.2631, -0.0746,  0.0140, -0.4683,  0.2201, -0.0682],\n",
      "        [ 0.2585, -0.2330, -0.1002, -0.1192, -0.3002, -0.0311,  0.2307],\n",
      "        [ 0.4637, -0.1764, -0.1424, -0.1873, -0.4247, -0.0229, -0.0396],\n",
      "        [ 0.3281, -0.0539, -0.1536, -0.1103, -0.4477,  0.0560,  0.0515],\n",
      "        [ 0.3094, -0.1715, -0.1380, -0.3118, -0.5039,  0.0168,  0.1768],\n",
      "        [ 0.3267, -0.2312, -0.0950, -0.1819, -0.3969, -0.0166,  0.0071],\n",
      "        [ 0.2635, -0.2605, -0.1908, -0.1098, -0.2785, -0.0077, -0.0303]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.3417, -0.2315, -0.1334, -0.0260, -0.3942, -0.0138,  0.0566],\n",
      "        [ 0.3750, -0.2098, -0.1516, -0.0884, -0.2967, -0.0393,  0.0394],\n",
      "        [ 0.2320, -0.1273, -0.0648, -0.2629, -0.4127,  0.0100,  0.1328],\n",
      "        [ 0.2248, -0.1122, -0.1101, -0.1859, -0.1697,  0.0863,  0.1514],\n",
      "        [ 0.3157, -0.2978, -0.2355, -0.0963, -0.3792,  0.0689,  0.0383],\n",
      "        [ 0.2293, -0.2663, -0.1880, -0.1018, -0.2899,  0.1498,  0.2092],\n",
      "        [ 0.2309, -0.2328, -0.0600, -0.0418, -0.2754,  0.0998, -0.0071],\n",
      "        [ 0.2626, -0.2416, -0.2221, -0.1571, -0.3039,  0.0137,  0.0672],\n",
      "        [ 0.1928, -0.2635, -0.1682, -0.0812, -0.3480,  0.1177,  0.2119],\n",
      "        [ 0.2148, -0.2251, -0.1898, -0.1260, -0.3992,  0.0635,  0.1187],\n",
      "        [ 0.3043, -0.2877, -0.1716, -0.1884, -0.4251, -0.0498,  0.0454],\n",
      "        [ 0.2921, -0.2259, -0.1364, -0.0690, -0.4678, -0.0709,  0.0285],\n",
      "        [ 0.2794, -0.1479, -0.2205, -0.0986, -0.3476,  0.0985,  0.0750],\n",
      "        [ 0.3413,  0.1109, -0.0297, -0.1975, -0.2880, -0.0394,  0.0652],\n",
      "        [ 0.2258, -0.1966, -0.0119, -0.2362, -0.3532,  0.1825,  0.2019],\n",
      "        [ 0.2627, -0.1260,  0.0392, -0.0830, -0.2949,  0.1236,  0.0986]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 3.6291e-01, -2.3185e-01, -1.7782e-01, -1.6702e-01, -4.3547e-01,\n",
      "         -2.8670e-02,  4.4302e-02],\n",
      "        [ 4.1090e-01, -1.5787e-01, -2.0972e-01, -4.1415e-02, -3.1807e-01,\n",
      "         -8.4009e-02, -5.7157e-03],\n",
      "        [ 1.2850e-01,  1.3862e-02, -1.4133e-01, -2.8792e-01, -2.8506e-01,\n",
      "          2.3898e-01,  1.7508e-01],\n",
      "        [ 2.9900e-01,  7.1667e-02, -1.8244e-01, -8.8203e-02, -3.0986e-01,\n",
      "          1.0820e-01,  9.0076e-02],\n",
      "        [ 1.4592e-01, -3.4803e-01, -1.8837e-01, -1.2415e-01, -3.4000e-01,\n",
      "          1.5101e-01,  2.4803e-01],\n",
      "        [ 3.1272e-01, -2.6458e-01, -2.4743e-01, -1.4009e-01, -3.6262e-01,\n",
      "          2.6998e-02,  1.1023e-01],\n",
      "        [ 1.3488e-01, -2.9236e-01, -2.2949e-01, -2.1387e-01, -3.3665e-01,\n",
      "          8.2337e-02,  2.4870e-01],\n",
      "        [ 2.2254e-01, -1.0892e-01, -9.0240e-02, -2.3880e-01, -2.7712e-01,\n",
      "          7.8359e-02,  1.3493e-01],\n",
      "        [ 3.3620e-01, -2.2300e-01, -9.7052e-02, -5.6226e-02, -3.7422e-01,\n",
      "         -4.3685e-03, -3.6499e-05],\n",
      "        [ 2.5882e-01,  8.7088e-02, -1.5864e-01, -9.6612e-02, -3.1685e-01,\n",
      "          1.2775e-01,  1.2193e-01],\n",
      "        [ 2.9301e-01, -2.2352e-01,  5.1683e-03, -9.4177e-02, -2.4251e-01,\n",
      "          1.1145e-01, -2.3109e-02],\n",
      "        [ 1.3900e-01, -1.3214e-01, -7.2171e-02, -2.3882e-01, -3.3622e-01,\n",
      "          1.8485e-01,  2.3791e-04],\n",
      "        [ 2.4010e-01, -1.9677e-01, -8.0360e-02, -1.3150e-01, -2.5675e-01,\n",
      "          1.5497e-01,  1.2571e-01],\n",
      "        [ 1.8026e-01, -3.2609e-01, -2.1162e-01, -9.8608e-02, -4.6425e-01,\n",
      "          7.5965e-02,  2.3757e-01],\n",
      "        [ 2.3733e-01, -3.6578e-01, -1.0829e-01, -5.9550e-02, -3.1904e-01,\n",
      "          1.8882e-01,  1.3562e-01],\n",
      "        [ 2.7329e-01, -2.9472e-01, -8.6096e-02, -1.6561e-01, -3.6128e-01,\n",
      "          6.5584e-02,  9.2812e-02]], device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.3537, -0.0858, -0.1783, -0.1506, -0.2484, -0.0096,  0.2214],\n",
      "        [ 0.3305, -0.1848, -0.1796, -0.0773, -0.3903, -0.0455,  0.0105],\n",
      "        [ 0.3002, -0.1860, -0.1609, -0.1322, -0.3953, -0.1061, -0.0448],\n",
      "        [ 0.1369, -0.1261, -0.1439, -0.3319, -0.3519,  0.1964,  0.0893],\n",
      "        [ 0.1265, -0.0989, -0.0964, -0.2525, -0.3622,  0.1901,  0.0319],\n",
      "        [ 0.1885, -0.2491, -0.1429, -0.0679, -0.3362,  0.1373,  0.2245],\n",
      "        [ 0.3917, -0.1153, -0.1891,  0.0175, -0.3207, -0.0072,  0.0453],\n",
      "        [ 0.2310, -0.2567, -0.2095, -0.1005, -0.3104,  0.1465,  0.2236],\n",
      "        [ 0.2513, -0.1543, -0.0949, -0.0493, -0.1504,  0.0913,  0.0985],\n",
      "        [ 0.3493, -0.2370,  0.0368, -0.1505, -0.3550, -0.0278, -0.0691],\n",
      "        [ 0.3863, -0.1232, -0.1335, -0.1903, -0.4362,  0.0238, -0.0249],\n",
      "        [ 0.3273, -0.1901, -0.1592, -0.1275, -0.3068, -0.0541, -0.0307],\n",
      "        [ 0.2362, -0.0886, -0.1455, -0.2551, -0.2745,  0.1532,  0.1354],\n",
      "        [ 0.2464, -0.1497, -0.1765, -0.1140, -0.2504,  0.0367,  0.1607],\n",
      "        [ 0.2997, -0.1800, -0.0895, -0.0878, -0.3490, -0.0195, -0.1148],\n",
      "        [ 0.2193,  0.1189, -0.3464, -0.1227, -0.3393,  0.0143,  0.1660]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2462, -0.1453, -0.1236, -0.1280, -0.2110,  0.0092,  0.0677],\n",
      "        [ 0.4052, -0.1661, -0.1855, -0.0345, -0.3857, -0.0686,  0.0965],\n",
      "        [ 0.2844, -0.2099, -0.2007, -0.0443, -0.3813,  0.0628,  0.1055],\n",
      "        [ 0.1701, -0.2581, -0.1142, -0.2046, -0.2564,  0.0904,  0.2659],\n",
      "        [ 0.0741, -0.2576, -0.2398, -0.2107, -0.1959,  0.0893,  0.3093],\n",
      "        [ 0.1885, -0.2198, -0.1756, -0.0753, -0.3552,  0.0997,  0.2413],\n",
      "        [ 0.3092, -0.2334, -0.1007, -0.1257, -0.3630,  0.0440, -0.0056],\n",
      "        [ 0.2982, -0.0477, -0.1370, -0.1554, -0.4577,  0.0992, -0.0542],\n",
      "        [ 0.3219, -0.2411, -0.0811, -0.1568, -0.3486,  0.0777,  0.0395],\n",
      "        [ 0.2901, -0.1914, -0.1714, -0.0893, -0.2598,  0.0521,  0.1209],\n",
      "        [ 0.2717, -0.0454, -0.3258, -0.0177, -0.3072,  0.0833,  0.2270],\n",
      "        [ 0.1875, -0.2250, -0.1711, -0.2238, -0.3945,  0.0876,  0.2015],\n",
      "        [ 0.2791, -0.0986, -0.2997, -0.0316, -0.2798,  0.0962,  0.2317],\n",
      "        [ 0.1393, -0.2504, -0.1529, -0.2555, -0.2608,  0.0178,  0.2218],\n",
      "        [ 0.2616, -0.0310, -0.1690,  0.0026, -0.1918, -0.0207,  0.1999],\n",
      "        [ 0.2864, -0.2245, -0.0121, -0.1538, -0.2828,  0.0530, -0.0445]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.3706, -0.0848, -0.3118, -0.1082, -0.2876, -0.1103, -0.0104],\n",
      "        [ 0.1735, -0.2439, -0.1840, -0.0733, -0.3502,  0.1459,  0.2459],\n",
      "        [ 0.4116, -0.2334, -0.0014, -0.1263, -0.2569, -0.0754, -0.0503],\n",
      "        [ 0.2834, -0.1951, -0.0874, -0.1650, -0.2926, -0.0246,  0.1784],\n",
      "        [ 0.3878, -0.0937, -0.1210, -0.0652, -0.4596, -0.0174,  0.1136],\n",
      "        [ 0.3450, -0.2374, -0.1909, -0.0925, -0.3050, -0.0172,  0.0793],\n",
      "        [ 0.1622, -0.3328, -0.1681, -0.2034, -0.2316,  0.0700,  0.1942],\n",
      "        [ 0.2713, -0.0906, -0.3673, -0.0393, -0.3101,  0.0892,  0.2018],\n",
      "        [ 0.2966, -0.0823, -0.2688, -0.0621, -0.3648,  0.0158,  0.0723],\n",
      "        [ 0.1425, -0.3026, -0.1998, -0.1328, -0.2896,  0.0250,  0.2361],\n",
      "        [ 0.1711, -0.1507, -0.1008, -0.2673, -0.3714,  0.1416, -0.0297],\n",
      "        [ 0.1876, -0.2455, -0.2633, -0.1311, -0.3305,  0.1003,  0.2161],\n",
      "        [ 0.2489, -0.1615, -0.1597, -0.0643, -0.2889,  0.2409,  0.0287],\n",
      "        [ 0.3083, -0.2429, -0.1498, -0.2136, -0.2592, -0.1461,  0.1932],\n",
      "        [ 0.2917, -0.2573, -0.0720,  0.0183, -0.4786,  0.2202, -0.0714],\n",
      "        [ 0.3802, -0.0691, -0.1989, -0.0258, -0.3169, -0.0589,  0.1114]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.3418, -0.1602, -0.2098, -0.1495, -0.4005, -0.0318, -0.0617],\n",
      "        [ 0.2242, -0.2617, -0.1268, -0.2512, -0.3672,  0.0510,  0.0971],\n",
      "        [ 0.3595, -0.2403, -0.2096, -0.1547, -0.2951, -0.0506,  0.0523],\n",
      "        [ 0.3079, -0.2043, -0.1238, -0.2595, -0.4143, -0.0011,  0.1780],\n",
      "        [ 0.3763, -0.1849, -0.2296, -0.0487, -0.3730, -0.0446,  0.0585],\n",
      "        [ 0.2152, -0.2219, -0.2427, -0.1755, -0.2712,  0.0667,  0.1065],\n",
      "        [ 0.4004, -0.1844,  0.0150, -0.1596, -0.2993, -0.0935, -0.0779],\n",
      "        [ 0.2172, -0.2380, -0.2528, -0.1240, -0.3109,  0.0746,  0.2328],\n",
      "        [ 0.1770, -0.2614, -0.0856, -0.2377, -0.2247,  0.1441,  0.1912],\n",
      "        [ 0.2033, -0.0756, -0.0360, -0.1203, -0.2763,  0.1389,  0.0865],\n",
      "        [ 0.3153, -0.0896, -0.2948,  0.0180, -0.3139,  0.0750,  0.1464],\n",
      "        [ 0.2374, -0.2777, -0.2299, -0.0759, -0.4831, -0.0447,  0.1468],\n",
      "        [ 0.3093,  0.0201,  0.0752,  0.0872, -0.1704, -0.3375,  0.0739],\n",
      "        [ 0.1905, -0.3127, -0.0129, -0.0700, -0.3366,  0.0822, -0.0204],\n",
      "        [ 0.1755, -0.0592, -0.0757, -0.2130, -0.2615,  0.2054,  0.2792],\n",
      "        [ 0.3279, -0.1394, -0.1799, -0.1426, -0.2389, -0.0071, -0.0160]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 2.3659e-01,  4.1756e-02, -2.7518e-01, -1.3176e-01, -2.7074e-01,\n",
      "          7.3093e-02,  6.5989e-02],\n",
      "        [ 3.5456e-01, -1.6850e-01, -9.8306e-02, -1.1919e-01, -3.3238e-01,\n",
      "         -3.0750e-02, -4.1891e-04],\n",
      "        [ 2.5011e-01, -4.8878e-02, -3.6133e-01, -5.7836e-02, -2.9074e-01,\n",
      "          1.1867e-01,  2.3059e-01],\n",
      "        [ 3.6198e-01, -1.9327e-01, -1.8451e-01, -1.6593e-01, -3.3105e-01,\n",
      "          2.5793e-03, -1.7758e-02],\n",
      "        [ 3.4050e-01, -2.5334e-01, -2.8333e-02, -1.7915e-02, -3.8677e-01,\n",
      "         -1.2017e-01,  1.6032e-02],\n",
      "        [ 1.9880e-01, -2.4323e-01, -5.6265e-02, -2.8943e-02, -1.7455e-01,\n",
      "          1.0169e-01,  1.3534e-01],\n",
      "        [ 2.5436e-01, -1.3117e-01, -1.9366e-01, -1.4622e-01, -2.5885e-01,\n",
      "          2.7994e-02,  5.3269e-02],\n",
      "        [ 2.3090e-01, -2.2785e-02, -1.9068e-01, -1.4312e-01, -4.3461e-01,\n",
      "          1.2001e-01,  2.5585e-02],\n",
      "        [ 3.4792e-01, -1.5124e-01, -1.2922e-01, -3.1232e-01, -4.7505e-01,\n",
      "         -5.7627e-03,  1.4956e-01],\n",
      "        [ 2.9266e-01, -2.1695e-01,  2.0586e-02, -2.4631e-01, -2.4346e-01,\n",
      "          1.3080e-01,  1.6586e-01],\n",
      "        [ 4.3396e-01, -2.5284e-01, -4.9616e-02, -1.8801e-01, -4.7298e-01,\n",
      "          5.6359e-02,  2.1332e-01],\n",
      "        [ 2.6689e-01, -3.5765e-01, -4.8044e-02, -2.3733e-01, -1.7273e-01,\n",
      "          1.2201e-01,  6.4649e-02],\n",
      "        [ 2.3099e-01, -2.5672e-01, -2.0950e-01, -1.0045e-01, -3.1035e-01,\n",
      "          1.4651e-01,  2.2358e-01],\n",
      "        [ 2.4759e-01, -2.8677e-01, -2.1741e-01, -2.0919e-01, -3.4606e-01,\n",
      "         -9.7969e-03,  8.0764e-02],\n",
      "        [ 2.7235e-01, -2.4189e-01, -1.0218e-01, -1.6351e-01, -2.3733e-01,\n",
      "          1.1263e-01,  1.4666e-01],\n",
      "        [ 3.0924e-01, -1.7339e-01, -1.2069e-01, -1.5784e-01, -3.1297e-01,\n",
      "          2.0936e-02,  4.5758e-02]], device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.2017, -0.3237, -0.1321, -0.2346, -0.2555, -0.0206,  0.0902],\n",
      "        [ 0.2961, -0.2385, -0.1249, -0.2824, -0.3952,  0.0721,  0.0618],\n",
      "        [ 0.3351, -0.2524, -0.0830, -0.1704, -0.3138,  0.0579,  0.0247],\n",
      "        [ 0.2759, -0.2018, -0.1485, -0.1075, -0.3515,  0.0097,  0.0361],\n",
      "        [ 0.3220, -0.1439, -0.1321, -0.0424, -0.2919, -0.0284,  0.0776],\n",
      "        [ 0.1276, -0.2428, -0.2368, -0.1980, -0.3388,  0.0653,  0.2903],\n",
      "        [ 0.1971, -0.2283, -0.1935, -0.1942, -0.3384,  0.0942,  0.1952],\n",
      "        [ 0.2873, -0.2550, -0.0484, -0.2558, -0.3022, -0.0055,  0.1117],\n",
      "        [ 0.1896, -0.2798, -0.1924, -0.2263, -0.3146,  0.1141,  0.2774],\n",
      "        [ 0.3347, -0.0764, -0.1157, -0.1707, -0.3699,  0.0278,  0.0462],\n",
      "        [ 0.1331, -0.2683, -0.1212, -0.2447, -0.2202,  0.0772,  0.2512],\n",
      "        [ 0.4072, -0.1064, -0.0497, -0.0291, -0.4640, -0.0154, -0.0516],\n",
      "        [ 0.1876, -0.1360, -0.2823, -0.2897, -0.2562,  0.2328,  0.0707],\n",
      "        [ 0.2624,  0.0403, -0.2118, -0.0430, -0.3213,  0.1189,  0.1422],\n",
      "        [ 0.1512, -0.2731, -0.2292, -0.1071, -0.2910,  0.0051,  0.2209],\n",
      "        [ 0.3346, -0.2195, -0.0866, -0.2079, -0.4092,  0.0350,  0.1010]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.2515, -0.2224, -0.1795, -0.1639, -0.3776,  0.0582,  0.1452],\n",
      "        [ 0.3452, -0.1694, -0.1993, -0.0825, -0.3604, -0.0957, -0.0414],\n",
      "        [ 0.3015, -0.1015, -0.0748, -0.1825, -0.3526,  0.0477,  0.1041],\n",
      "        [ 0.2025, -0.1061, -0.2465, -0.1463, -0.3095,  0.2149,  0.0919],\n",
      "        [ 0.2399, -0.1941, -0.0514, -0.2659, -0.2623,  0.1656,  0.2602],\n",
      "        [ 0.3012, -0.2104, -0.2499, -0.1464, -0.3562,  0.0503,  0.0273],\n",
      "        [ 0.1976, -0.3433, -0.2077, -0.1601, -0.3407,  0.0570,  0.2463],\n",
      "        [ 0.2147, -0.2467, -0.2080, -0.1192, -0.2978,  0.1410,  0.2160],\n",
      "        [ 0.2671, -0.2503, -0.1706, -0.1267, -0.4244, -0.0284,  0.0948],\n",
      "        [ 0.2598, -0.0774, -0.1443, -0.1485, -0.2443,  0.0632,  0.0683],\n",
      "        [ 0.2194, -0.2509, -0.2144, -0.1061, -0.2986,  0.1393,  0.2128],\n",
      "        [ 0.2131, -0.2175, -0.1478, -0.1864, -0.3515,  0.0930,  0.2566],\n",
      "        [ 0.3470, -0.2303, -0.1454, -0.0489, -0.3354, -0.0031,  0.0619],\n",
      "        [ 0.2583, -0.0727, -0.3532, -0.0402, -0.2816,  0.0991,  0.2092],\n",
      "        [ 0.3763, -0.1849, -0.2296, -0.0487, -0.3730, -0.0446,  0.0585],\n",
      "        [ 0.1498, -0.2687, -0.2084, -0.1834, -0.2073,  0.1038,  0.2061]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2994, -0.2316, -0.2579, -0.1525, -0.3591,  0.0224,  0.0439],\n",
      "        [ 0.3701, -0.1330, -0.1967, -0.1224, -0.2929, -0.0608,  0.0166],\n",
      "        [ 0.1834, -0.2619, -0.1863, -0.0963, -0.3483,  0.1356,  0.2003],\n",
      "        [ 0.2213, -0.3019, -0.1602, -0.1582, -0.2985, -0.0176,  0.2226],\n",
      "        [ 0.2020, -0.3837, -0.2963, -0.1861, -0.4291, -0.0565,  0.0748],\n",
      "        [ 0.3272, -0.2375, -0.2122, -0.1228, -0.3605,  0.0628,  0.1163],\n",
      "        [ 0.3387, -0.1631, -0.1460, -0.1583, -0.3296,  0.0712,  0.0504],\n",
      "        [ 0.2621, -0.1232, -0.0454, -0.0285, -0.1935,  0.0630,  0.0979],\n",
      "        [ 0.3437, -0.2529, -0.0269, -0.1343, -0.3349, -0.0579, -0.0333],\n",
      "        [ 0.2651, -0.2444, -0.1112, -0.1553, -0.2332,  0.1077,  0.1397],\n",
      "        [ 0.2870, -0.2563, -0.0746,  0.0126, -0.4785,  0.2255, -0.0691],\n",
      "        [ 0.2883, -0.0819, -0.1395, -0.2586, -0.2827,  0.1565, -0.0097],\n",
      "        [ 0.2892, -0.1522, -0.2046, -0.1282, -0.3380,  0.0299,  0.0027],\n",
      "        [ 0.1962, -0.2416, -0.1700, -0.1721, -0.2417,  0.1190,  0.1434],\n",
      "        [ 0.1916, -0.2552, -0.1586, -0.1048, -0.3494,  0.1278,  0.2442],\n",
      "        [ 0.2821, -0.0219, -0.1563, -0.0728, -0.3196,  0.1390,  0.1438]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.1698, -0.1977, -0.1229, -0.1792, -0.2192,  0.0234,  0.2314],\n",
      "        [ 0.1992, -0.2550, -0.1595, -0.0988, -0.3368,  0.1199,  0.2241],\n",
      "        [ 0.3046, -0.3584, -0.1570, -0.0961, -0.4586,  0.0396,  0.1231],\n",
      "        [ 0.2546,  0.0625, -0.1720, -0.0637, -0.3377,  0.1335,  0.0665],\n",
      "        [ 0.1903, -0.3546, -0.2424, -0.1517, -0.3839,  0.0737,  0.1937],\n",
      "        [ 0.2527,  0.0926, -0.1316, -0.0899, -0.3221,  0.0633,  0.0716],\n",
      "        [ 0.3437, -0.3204, -0.1584, -0.0907, -0.2586, -0.0123, -0.0075],\n",
      "        [ 0.1947, -0.2970, -0.0767, -0.0992, -0.2961,  0.0259,  0.2704],\n",
      "        [ 0.2731,  0.1217, -0.0920, -0.0075, -0.5608,  0.0392, -0.0529],\n",
      "        [ 0.3378, -0.2522, -0.1152, -0.0733, -0.3805, -0.0567,  0.1024],\n",
      "        [ 0.2095, -0.2308, -0.1434, -0.1710, -0.3157,  0.0840,  0.2862],\n",
      "        [ 0.1860, -0.2561, -0.1546, -0.0787, -0.3488,  0.1233,  0.2257],\n",
      "        [ 0.3525, -0.3238, -0.2207, -0.1432, -0.3978, -0.0848,  0.0371],\n",
      "        [ 0.3125, -0.1597, -0.0325, -0.1204, -0.3398,  0.1041,  0.0242],\n",
      "        [ 0.2772, -0.3057, -0.2002, -0.1163, -0.4187, -0.0045,  0.1271],\n",
      "        [ 0.2093, -0.2563, -0.1740, -0.2014, -0.3301,  0.0972,  0.2548]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.1849, -0.2515, -0.1482, -0.1546, -0.3305,  0.0795,  0.2678],\n",
      "        [ 0.4438, -0.0527, -0.1638, -0.1785, -0.4560, -0.1153, -0.0372],\n",
      "        [ 0.1918, -0.3119, -0.0455, -0.2660, -0.3832,  0.2229,  0.2379],\n",
      "        [ 0.2441,  0.0761, -0.1516, -0.1074, -0.2888,  0.1125,  0.1385],\n",
      "        [ 0.2805, -0.1885, -0.1790, -0.0659, -0.3682,  0.1029,  0.1852],\n",
      "        [ 0.3506,  0.0033, -0.1593,  0.0310, -0.3140,  0.0686,  0.0848],\n",
      "        [ 0.2255,  0.0919, -0.1339, -0.0851, -0.2817,  0.1262,  0.1276],\n",
      "        [ 0.1458, -0.0745, -0.1359, -0.3374, -0.3812,  0.1986,  0.0994],\n",
      "        [ 0.1591, -0.3225, -0.1931, -0.1240, -0.3877,  0.1443,  0.2646],\n",
      "        [ 0.3546, -0.1250, -0.1531, -0.0505, -0.3115, -0.0081,  0.0519],\n",
      "        [ 0.2587, -0.2206, -0.0625, -0.1943, -0.3805,  0.0969,  0.1298],\n",
      "        [ 0.2952, -0.3251, -0.1231, -0.1770, -0.3879, -0.0247,  0.1173],\n",
      "        [ 0.1931, -0.2312, -0.1597, -0.0692, -0.3514,  0.1133,  0.2321],\n",
      "        [ 0.3145, -0.1171, -0.1857, -0.1722, -0.3536,  0.0698, -0.0206],\n",
      "        [ 0.2868, -0.2447, -0.2456, -0.1991, -0.3612,  0.0232,  0.0830],\n",
      "        [ 0.4123, -0.0750, -0.1327, -0.1909, -0.2797, -0.0919,  0.0147]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.2388, -0.2374, -0.0102, -0.0776, -0.1465,  0.0523,  0.2297],\n",
      "        [ 0.2532, -0.2029, -0.2099, -0.1730, -0.4290,  0.0623,  0.0899],\n",
      "        [ 0.2045, -0.3337, -0.1992, -0.0984, -0.4506,  0.0512,  0.1844],\n",
      "        [ 0.2527, -0.1616, -0.0701, -0.1448, -0.2547,  0.0856,  0.1471],\n",
      "        [ 0.3169, -0.1003, -0.1484, -0.2343, -0.4393,  0.0007, -0.0138],\n",
      "        [ 0.2833, -0.2636, -0.1283, -0.2104, -0.3891,  0.0328,  0.0961],\n",
      "        [ 0.2433, -0.1923, -0.0740, -0.1320, -0.2590,  0.1460,  0.1286],\n",
      "        [ 0.2259, -0.0225, -0.0884, -0.1904, -0.4183,  0.1207,  0.1064],\n",
      "        [ 0.2937,  0.0110, -0.1180, -0.0774, -0.2595,  0.1784,  0.1723],\n",
      "        [ 0.2677, -0.1553, -0.1420, -0.0217, -0.3751,  0.0322,  0.1984],\n",
      "        [ 0.2855,  0.0710, -0.0376, -0.1948, -0.3181, -0.0313,  0.1007],\n",
      "        [ 0.3021, -0.3190, -0.1675, -0.2109, -0.3424, -0.0009,  0.0739],\n",
      "        [ 0.3800, -0.2220, -0.1786, -0.0813, -0.3207,  0.0173,  0.0614],\n",
      "        [ 0.2088, -0.1112, -0.0859, -0.2446, -0.2220,  0.1821, -0.0348],\n",
      "        [ 0.3635, -0.0537, -0.2096, -0.0469, -0.3976, -0.0172, -0.1610],\n",
      "        [ 0.2073, -0.2176, -0.2593, -0.1282, -0.3125,  0.0217,  0.2285]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.1792, -0.2082, -0.0940, -0.2387, -0.3441,  0.0946,  0.2171],\n",
      "        [ 0.1809, -0.3575, -0.2388, -0.1522, -0.3783,  0.1095,  0.1927],\n",
      "        [ 0.2267, -0.2339, -0.2096, -0.1157, -0.2751,  0.1435,  0.2428],\n",
      "        [ 0.2208, -0.2570, -0.1539, -0.1053, -0.2183,  0.0500,  0.0549],\n",
      "        [ 0.1982, -0.2581, -0.1694, -0.0552, -0.3719,  0.0953,  0.2326],\n",
      "        [ 0.2140, -0.3428, -0.1898, -0.1373, -0.3667,  0.1336,  0.2212],\n",
      "        [ 0.2472, -0.3314, -0.2023, -0.1370, -0.3752,  0.1303,  0.2048],\n",
      "        [ 0.3267, -0.2868, -0.2058, -0.1600, -0.3833, -0.0126,  0.1339],\n",
      "        [ 0.3231, -0.2209, -0.1393, -0.1488, -0.3646, -0.0682,  0.0006],\n",
      "        [ 0.1753, -0.2112, -0.0882, -0.1965, -0.3339,  0.0762,  0.2363],\n",
      "        [ 0.2188, -0.1919, -0.0800, -0.1307, -0.2595,  0.1593,  0.1343],\n",
      "        [ 0.1354, -0.0472, -0.1758, -0.2875, -0.2707,  0.2616,  0.1965],\n",
      "        [ 0.3426, -0.2069, -0.1601, -0.0241, -0.2936,  0.0405,  0.0860],\n",
      "        [ 0.1863, -0.3381, -0.2562, -0.1443, -0.3858,  0.1252,  0.2101],\n",
      "        [ 0.1135, -0.2331, -0.2277, -0.2307, -0.1925,  0.0141,  0.2491],\n",
      "        [ 0.1877, -0.3452, -0.2394, -0.1420, -0.3882,  0.1129,  0.2229]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.2106, -0.1518, -0.2307, -0.1366, -0.3399,  0.0314,  0.0924],\n",
      "        [ 0.1765, -0.0697, -0.0753, -0.1428, -0.2650,  0.1211,  0.0936],\n",
      "        [ 0.2920, -0.2593, -0.0626,  0.0107, -0.4741,  0.2178, -0.0716],\n",
      "        [ 0.3638,  0.1461, -0.0822, -0.1202, -0.3874, -0.0377, -0.0455],\n",
      "        [ 0.1588, -0.1045, -0.0447, -0.1622, -0.2229,  0.1093,  0.1740],\n",
      "        [ 0.2763, -0.2891, -0.2084, -0.2067, -0.3385,  0.0288,  0.2569],\n",
      "        [ 0.4042, -0.1832, -0.1513, -0.0853, -0.3379, -0.1384,  0.0158],\n",
      "        [ 0.2103,  0.0683, -0.0870,  0.0400, -0.5130,  0.1097, -0.0109],\n",
      "        [ 0.3395, -0.1695, -0.1761, -0.0659, -0.3202, -0.0019,  0.0498],\n",
      "        [ 0.1812, -0.1089, -0.1264, -0.3480, -0.3465,  0.2224,  0.0579],\n",
      "        [ 0.2598, -0.1617, -0.0768, -0.1845, -0.2577,  0.0275,  0.1281],\n",
      "        [ 0.2383, -0.1077, -0.1374, -0.1612, -0.2211,  0.0322,  0.0717],\n",
      "        [ 0.2297, -0.2052, -0.0740, -0.1675, -0.3056,  0.1366,  0.1757],\n",
      "        [ 0.3463,  0.0781, -0.1963, -0.1428, -0.4018,  0.0964, -0.0365],\n",
      "        [ 0.2923,  0.0780, -0.0860,  0.0595, -0.5923,  0.0188, -0.0761],\n",
      "        [ 0.3322,  0.0350, -0.1268,  0.0496, -0.2773,  0.0854,  0.1170]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.2641, -0.1108, -0.1099, -0.1385, -0.2248,  0.0326,  0.0663],\n",
      "        [ 0.0954, -0.2735, -0.2566, -0.2376, -0.3008, -0.0177,  0.2180],\n",
      "        [ 0.2237, -0.1472, -0.1639, -0.2504, -0.2645,  0.1505,  0.0619],\n",
      "        [ 0.2086, -0.2035, -0.3149, -0.1693, -0.3459,  0.0452,  0.0329],\n",
      "        [ 0.4277, -0.1006, -0.1060, -0.1520, -0.4902, -0.1032, -0.0539],\n",
      "        [ 0.3063, -0.2049, -0.1072, -0.0921, -0.2903,  0.0488,  0.0020],\n",
      "        [ 0.1888, -0.1629, -0.0434, -0.2760, -0.3887,  0.1889,  0.1557],\n",
      "        [ 0.4013, -0.2772, -0.2589, -0.1357, -0.3605, -0.0783, -0.0578],\n",
      "        [ 0.2662, -0.0726, -0.3364, -0.0465, -0.2753,  0.1095,  0.2187],\n",
      "        [ 0.2634,  0.0886, -0.1575, -0.0931, -0.3151,  0.1260,  0.1181],\n",
      "        [ 0.3709, -0.1876, -0.1316, -0.1303, -0.3124,  0.0491,  0.0701],\n",
      "        [ 0.3296, -0.2070, -0.1451, -0.1530, -0.4320,  0.0091,  0.0726],\n",
      "        [ 0.2710, -0.2991, -0.2650, -0.2194, -0.2909, -0.0102,  0.1278],\n",
      "        [ 0.2378, -0.2079, -0.1253, -0.1761, -0.3239,  0.1116,  0.2860],\n",
      "        [ 0.2480, -0.2091, -0.1908, -0.0895, -0.3082,  0.0924,  0.1836],\n",
      "        [ 0.2225, -0.2901, -0.1899, -0.1187, -0.2833,  0.1514,  0.1818]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.5390e-01, -1.8118e-01,  1.6996e-02, -8.3232e-02, -2.1133e-01,\n",
      "          1.1528e-01,  9.4147e-02],\n",
      "        [ 3.6496e-01,  6.5263e-02, -9.5154e-02, -2.9278e-01, -4.5829e-01,\n",
      "          2.0662e-01, -5.3537e-02],\n",
      "        [ 2.7138e-01,  1.1942e-02,  2.2219e-04, -2.2258e-01, -3.1216e-01,\n",
      "         -7.0005e-02,  7.8048e-02],\n",
      "        [ 1.7364e-01, -2.7446e-01, -1.7379e-02, -2.3706e-01, -2.0423e-01,\n",
      "          4.7542e-02,  1.8480e-01],\n",
      "        [ 2.7645e-01, -2.5093e-01, -1.7037e-01, -1.9409e-01, -3.3925e-01,\n",
      "          3.8763e-02,  8.5916e-02],\n",
      "        [ 2.6145e-01, -2.4202e-01, -7.6329e-02, -8.1567e-02, -2.3540e-01,\n",
      "          3.9976e-02,  3.4762e-02],\n",
      "        [ 3.3013e-01,  1.2392e-01, -5.7740e-02, -8.1737e-02, -3.2944e-01,\n",
      "          4.4428e-02,  9.7522e-02],\n",
      "        [ 2.3712e-01, -2.7147e-01, -2.7428e-03, -7.3397e-02, -1.2248e-01,\n",
      "          7.3165e-02,  1.2975e-01],\n",
      "        [ 3.0923e-01, -1.9293e-01, -2.1727e-01, -1.4150e-01, -3.5055e-01,\n",
      "          2.6117e-02, -7.1998e-03],\n",
      "        [ 3.2280e-01, -1.6520e-01, -2.0220e-01, -7.5748e-03, -3.8612e-01,\n",
      "         -1.8235e-02,  8.1019e-02],\n",
      "        [ 2.9495e-01, -2.9239e-01, -1.9273e-01, -1.5046e-01, -3.7903e-01,\n",
      "         -4.1739e-02,  1.0533e-01],\n",
      "        [ 1.8245e-01, -2.5930e-01, -1.8384e-01, -8.8446e-02, -3.4892e-01,\n",
      "          1.3091e-01,  2.3059e-01],\n",
      "        [ 3.5588e-01, -3.4437e-01, -4.1090e-02, -1.6540e-01, -3.5106e-01,\n",
      "          9.8559e-02,  3.6726e-02],\n",
      "        [ 2.9832e-01, -3.2164e-01, -4.7357e-02, -3.4981e-01, -3.3722e-01,\n",
      "          1.6496e-01,  1.8025e-01],\n",
      "        [ 1.8861e-01, -3.0410e-01, -1.9033e-01, -1.8393e-01, -3.0652e-01,\n",
      "          2.7586e-02,  2.7651e-01],\n",
      "        [ 2.6048e-01, -2.6065e-01, -6.7916e-02, -2.2417e-01, -4.1288e-01,\n",
      "          3.4720e-02,  8.6685e-03]], device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.2371, -0.2240, -0.1980, -0.2131, -0.2040,  0.0915,  0.1581],\n",
      "        [ 0.1617, -0.1624, -0.0749, -0.1618, -0.2388,  0.0643,  0.2471],\n",
      "        [ 0.2273, -0.3406, -0.1792, -0.1949, -0.3079, -0.0400,  0.0466],\n",
      "        [ 0.1908, -0.3412, -0.2686, -0.1564, -0.3946,  0.1084,  0.1976],\n",
      "        [ 0.5159, -0.2614, -0.1046, -0.3181, -0.2870,  0.0118,  0.0262],\n",
      "        [ 0.2288, -0.4006, -0.1002, -0.0806, -0.3050,  0.1848,  0.1115],\n",
      "        [ 0.2377, -0.1787, -0.2418, -0.1968, -0.3245,  0.0074,  0.0773],\n",
      "        [ 0.2634, -0.2603, -0.1733, -0.0841, -0.4455, -0.0613,  0.1411],\n",
      "        [ 0.2249, -0.1288, -0.0887, -0.0393, -0.3390,  0.1226,  0.1198],\n",
      "        [ 0.3773,  0.0525, -0.1529, -0.0078, -0.3365,  0.0505,  0.0250],\n",
      "        [ 0.4711, -0.2016, -0.0806, -0.2103, -0.4698,  0.0543,  0.1039],\n",
      "        [ 0.2418, -0.2192,  0.0011, -0.0469, -0.1726,  0.0572,  0.1632],\n",
      "        [ 0.3009, -0.2300, -0.1201, -0.1259, -0.2869,  0.0229,  0.0530],\n",
      "        [ 0.2378, -0.2013, -0.1256, -0.2181, -0.3641,  0.0117,  0.1387],\n",
      "        [ 0.3663, -0.0128, -0.0656, -0.1176, -0.2470,  0.1365,  0.0671],\n",
      "        [ 0.3566, -0.2612, -0.1359, -0.1105, -0.3386, -0.0570, -0.0321]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.3121, -0.1509, -0.0976, -0.0944, -0.2913,  0.0341, -0.0249],\n",
      "        [ 0.2922, -0.2888, -0.2179, -0.1652, -0.3295, -0.0008,  0.1779],\n",
      "        [ 0.2956, -0.2279, -0.1513, -0.1224, -0.3599,  0.0032,  0.0011],\n",
      "        [ 0.3374, -0.2285, -0.1614, -0.1355, -0.3532,  0.0306,  0.0496],\n",
      "        [ 0.1295, -0.3214, -0.2128, -0.1394, -0.2819,  0.0252,  0.2326],\n",
      "        [ 0.3139, -0.2022, -0.1523, -0.2200, -0.3978,  0.0062,  0.0354],\n",
      "        [ 0.2009, -0.3094, -0.1644, -0.0987, -0.2687,  0.1887,  0.1988],\n",
      "        [ 0.1250, -0.2096, -0.1094, -0.3207, -0.3755,  0.1386,  0.1945],\n",
      "        [ 0.1136, -0.3260, -0.1290, -0.1758, -0.3972,  0.2601,  0.1733],\n",
      "        [ 0.2742, -0.1928, -0.0803, -0.1286, -0.2595,  0.0153,  0.1509],\n",
      "        [ 0.3092, -0.1724, -0.1518, -0.0819, -0.4345, -0.0170, -0.0108],\n",
      "        [ 0.1660,  0.0141, -0.2853, -0.1247, -0.2718,  0.0931,  0.1646],\n",
      "        [ 0.3577, -0.0923, -0.0277, -0.1306, -0.4891,  0.0248, -0.0350],\n",
      "        [ 0.2590, -0.0634, -0.3529, -0.0391, -0.2798,  0.1200,  0.2180],\n",
      "        [ 0.3060, -0.2255, -0.0642, -0.2194, -0.3161,  0.1308,  0.1766],\n",
      "        [ 0.1918, -0.3220, -0.1655, -0.1020, -0.2461,  0.1870,  0.2133]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.3768, -0.2126, -0.2277, -0.1333, -0.3471, -0.0268, -0.0133],\n",
      "        [ 0.3090, -0.4042, -0.0412, -0.0588, -0.2166,  0.0496,  0.0280],\n",
      "        [ 0.2065, -0.2547, -0.1551, -0.0720, -0.3411,  0.1324,  0.2044],\n",
      "        [ 0.3054, -0.1638,  0.0063, -0.2418, -0.3913,  0.1083,  0.2181],\n",
      "        [ 0.1222, -0.2433, -0.2698, -0.2170, -0.2527,  0.0433,  0.2608],\n",
      "        [ 0.2976, -0.1278, -0.2452, -0.1200, -0.3437, -0.0086,  0.0591],\n",
      "        [ 0.3022, -0.3268, -0.1490, -0.1924, -0.3728,  0.0088,  0.0700],\n",
      "        [ 0.3478, -0.1765, -0.0387, -0.1501, -0.3591,  0.0620,  0.0107],\n",
      "        [ 0.3266, -0.2663, -0.0692, -0.1700, -0.2676,  0.0206,  0.0067],\n",
      "        [ 0.2780, -0.3272, -0.1901, -0.1466, -0.3620,  0.0772,  0.1774],\n",
      "        [ 0.1720, -0.0359, -0.1513, -0.2701, -0.2844,  0.2525,  0.1518],\n",
      "        [ 0.3575, -0.3087, -0.1607, -0.1656, -0.3613, -0.0578,  0.0102],\n",
      "        [ 0.1738, -0.3219, -0.2346, -0.1108, -0.4807,  0.0781,  0.2426],\n",
      "        [ 0.1918, -0.3220, -0.1655, -0.1020, -0.2461,  0.1870,  0.2133],\n",
      "        [ 0.3460, -0.2214, -0.1404, -0.0970, -0.3827, -0.0039,  0.0945],\n",
      "        [ 0.1853, -0.2369, -0.1550, -0.0780, -0.3417,  0.1243,  0.2278]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 0.2938, -0.1511, -0.0488, -0.1329, -0.3920,  0.1262,  0.1590],\n",
      "        [ 0.1462, -0.3235, -0.2018, -0.1807, -0.2159,  0.0922,  0.1965],\n",
      "        [ 0.2352, -0.2835, -0.1651, -0.0964, -0.2840,  0.1813,  0.2176],\n",
      "        [ 0.0959, -0.2490, -0.1545, -0.1804, -0.3677,  0.1764,  0.2600],\n",
      "        [ 0.2294, -0.1669, -0.2242, -0.1118, -0.3183, -0.0062, -0.0243],\n",
      "        [ 0.2086, -0.2046, -0.2025, -0.0661, -0.3622,  0.1420,  0.1936],\n",
      "        [ 0.3356, -0.1202, -0.0623, -0.0907, -0.4459, -0.0248, -0.1286],\n",
      "        [ 0.3608, -0.1875, -0.1588, -0.0620, -0.3409,  0.0553,  0.0487],\n",
      "        [ 0.2103, -0.1784, -0.1234, -0.2413, -0.4303,  0.0648,  0.2052],\n",
      "        [ 0.3044, -0.1345, -0.2508, -0.1137, -0.3988,  0.0298, -0.0164],\n",
      "        [ 0.2657, -0.1922, -0.1312, -0.1355, -0.3849, -0.0075, -0.0432],\n",
      "        [ 0.2927, -0.2169,  0.0206, -0.2463, -0.2435,  0.1308,  0.1659],\n",
      "        [ 0.1798, -0.2102, -0.1472, -0.2485, -0.2397,  0.1271,  0.1583],\n",
      "        [ 0.2577, -0.0742, -0.3544, -0.0283, -0.2849,  0.1024,  0.2072],\n",
      "        [ 0.3191, -0.1508, -0.0652, -0.2831, -0.3612,  0.0599,  0.1304],\n",
      "        [ 0.2665, -0.1153, -0.1943, -0.1213, -0.2333,  0.1967,  0.0479]],\n",
      "       device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n",
      "tensor([[ 3.5335e-01, -4.3405e-04, -1.6409e-01, -8.0191e-02, -3.4881e-01,\n",
      "          8.2832e-02,  6.2098e-02],\n",
      "        [ 2.1674e-01, -2.2133e-01, -2.2634e-01, -2.6070e-01, -2.2023e-01,\n",
      "          2.7008e-02,  2.5700e-01],\n",
      "        [ 2.9443e-01, -2.5785e-01, -7.1700e-02,  1.7503e-02, -4.7752e-01,\n",
      "          2.2109e-01, -6.9486e-02],\n",
      "        [ 3.3278e-01, -2.0399e-01, -1.3845e-01, -8.0798e-02, -3.1316e-01,\n",
      "         -7.1098e-02, -1.9379e-02],\n",
      "        [ 2.5986e-01, -2.0459e-01, -1.4901e-01, -1.2037e-01, -4.0260e-01,\n",
      "          1.0041e-01,  4.0629e-02],\n",
      "        [ 1.6364e-01, -2.4385e-01, -2.1644e-01, -2.4525e-01, -1.7821e-01,\n",
      "          6.2274e-02,  9.6436e-02],\n",
      "        [ 2.7218e-01, -4.4066e-01,  7.8590e-03, -1.0483e-01, -2.9391e-01,\n",
      "          9.0446e-02,  1.1458e-02],\n",
      "        [ 2.0641e-01,  2.7624e-02, -5.8354e-02, -3.0598e-01, -4.3948e-01,\n",
      "          1.1498e-01,  1.8340e-02],\n",
      "        [ 1.8032e-01, -2.6696e-01, -1.5181e-01, -7.8958e-02, -3.2743e-01,\n",
      "          1.4513e-01,  2.0633e-01],\n",
      "        [ 3.4240e-01, -1.8619e-01, -1.7173e-01, -4.7868e-02, -2.2189e-01,\n",
      "         -2.8681e-02,  7.4976e-02],\n",
      "        [ 1.0838e-01, -2.5186e-01, -1.0495e-01, -2.2989e-01, -2.3649e-01,\n",
      "          1.0795e-01,  2.7690e-01],\n",
      "        [ 1.8124e-01, -2.4220e-01, -1.5305e-01, -8.5931e-02, -3.3858e-01,\n",
      "          1.3929e-01,  2.3080e-01],\n",
      "        [ 2.9698e-01, -1.0158e-01, -1.3016e-01, -7.2723e-02, -3.0964e-01,\n",
      "          4.8614e-02,  1.5583e-02],\n",
      "        [ 3.7063e-01, -8.4758e-02, -3.1175e-01, -1.0822e-01, -2.8758e-01,\n",
      "         -1.1033e-01, -1.0369e-02],\n",
      "        [ 3.9781e-01, -2.2660e-01, -1.2452e-01, -1.8797e-01, -3.4208e-01,\n",
      "          5.6115e-02,  6.6614e-02],\n",
      "        [ 3.6213e-01, -2.3700e-02, -1.2857e-01, -3.4719e-02, -2.7866e-01,\n",
      "          8.2050e-02,  3.3497e-02]], device='cuda:0')\n",
      "first output 16\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([16, 7])\n",
      "output is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3050, -0.0751, -0.0660, -0.1555, -0.4698,  0.1354,  0.0830],\n",
      "        [ 0.3735, -0.2475, -0.1773, -0.1107, -0.3447, -0.0464,  0.0279],\n",
      "        [ 0.3336, -0.2469, -0.1641, -0.0575, -0.3678,  0.0070,  0.0844],\n",
      "        [ 0.2784, -0.2317, -0.1871, -0.0762, -0.2429,  0.1596,  0.1526],\n",
      "        [ 0.2758, -0.2705, -0.1534, -0.2343, -0.3614,  0.0030,  0.1478],\n",
      "        [ 0.2050, -0.2801, -0.1675, -0.0954, -0.2404,  0.2065,  0.2085],\n",
      "        [ 0.2013, -0.2093, -0.1943, -0.0578, -0.3691,  0.0876,  0.2172],\n",
      "        [ 0.2804, -0.3315, -0.0598, -0.1976, -0.3846,  0.0639,  0.0690],\n",
      "        [ 0.3146, -0.0719, -0.3004,  0.0098, -0.2794,  0.0885,  0.1450],\n",
      "        [ 0.2896, -0.0925, -0.1508, -0.1076, -0.2605,  0.0019,  0.2081],\n",
      "        [ 0.1454, -0.0951, -0.1139, -0.3485, -0.3785,  0.1608,  0.1113],\n",
      "        [ 0.2624, -0.2712, -0.0726, -0.1763, -0.4019,  0.1657,  0.1000],\n",
      "        [ 0.3212, -0.1025, -0.0955, -0.1469, -0.4150,  0.1346, -0.0037],\n",
      "        [ 0.1028, -0.2207, -0.1344, -0.1621, -0.2414,  0.1216,  0.1989],\n",
      "        [ 0.2631, -0.1826, -0.1423, -0.0784, -0.4656,  0.0842, -0.0324],\n",
      "        [ 0.2733, -0.2612,  0.0848, -0.1230, -0.3328, -0.0239,  0.1589]],\n",
      "       device='cuda:0')\n",
      "first output 8\n",
      "output pooler\n",
      "768\n",
      "after dropout  2\n",
      "after linear transformation  torch.Size([8, 7])\n",
      "output is\n",
      "tensor([[ 0.3449, -0.1684,  0.0353, -0.2608, -0.3350,  0.0158,  0.0941],\n",
      "        [ 0.3762, -0.1906, -0.0924, -0.0553, -0.3745, -0.0610, -0.0465],\n",
      "        [ 0.2585, -0.0862, -0.1506, -0.1513, -0.2418,  0.0564,  0.0643],\n",
      "        [ 0.1777, -0.2561, -0.1671, -0.1525, -0.2852,  0.0696,  0.2788],\n",
      "        [ 0.2144, -0.2482, -0.1872, -0.0609, -0.3554,  0.1202,  0.1942],\n",
      "        [ 0.2613, -0.0654, -0.3477, -0.0393, -0.2951,  0.0893,  0.2146],\n",
      "        [ 0.3920, -0.0767, -0.0379, -0.1418, -0.4484,  0.0208, -0.0030],\n",
      "        [ 0.3037, -0.2469, -0.0075, -0.1130, -0.2492,  0.0588, -0.0073]],\n",
      "       device='cuda:0')\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6836158633232117\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.6836158633232117}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model performance on the test dataset\n",
    "trainer.test(model,datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "7cb448c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 155923), started 1 day, 21:07:51 ago. (Use '!kill 155923' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8e73c8755db1be26\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8e73c8755db1be26\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the logs using tensorboard. #lightning_logs/\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "dffc3466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424, 424)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "4741ccd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fb198/BA/classification/multi_class/lightning_logs/version_8/checkpoints/Labels-epoch=09-val_loss=0.25-train_loss=0.32.ckpt'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retreive the checkpoint path for best model\n",
    "model_path = checkpoint_callback.best_model_path\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "8065070b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test samples = 424\n"
     ]
    }
   ],
   "source": [
    "#print(len(y_test), len(x_test))\n",
    "# Size of Test set\n",
    "print(f'Number of test samples = {len(x_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a84e9b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([424, 7])\n",
      "torch.Size([424, 512])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Tokenize all questions in x_test\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "\n",
    "for description in x_test:\n",
    "    encoded_quest = tokenizer.encode_plus(\n",
    "                    description,\n",
    "                    None,\n",
    "                    add_special_tokens=True,\n",
    "                    max_length= MAX_LEN,\n",
    "                    padding = 'max_length',\n",
    "                    return_token_type_ids= False,\n",
    "                    return_attention_mask= True,\n",
    "                    truncation=True,\n",
    "                    return_tensors = 'pt'      \n",
    "    )\n",
    "    # Add the input_ids from encoded question to the list.    \n",
    "    input_ids.append(encoded_quest['input_ids'])\n",
    "    # Add its attention mask \n",
    "    attention_masks.append(encoded_quest['attention_mask'])\n",
    "    \n",
    "# Now convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(binarizer.transform(y_test)) #y_test\n",
    "\n",
    "# Set the batch size.  \n",
    "TEST_BATCH_SIZE = 8  \n",
    "\n",
    "print(labels.shape)\n",
    "print(attention_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "cb9e4cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoader.\n",
    "pred_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "pred_sampler = SequentialSampler(pred_data)\n",
    "pred_dataloader = DataLoader(pred_data, sampler=pred_sampler, batch_size=TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0dacc725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424, 7) (424, 7)\n"
     ]
    }
   ],
   "source": [
    "# Put model in evaluation mode\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device) # moving model to cuda\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "pred_outs, true_labels = [], []\n",
    "#i=0\n",
    "# Predict \n",
    "for batch in pred_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_attn_mask, b_labels = batch\n",
    " \n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        pred_out = model(b_input_ids,b_attn_mask)\n",
    "        pred_out = torch.sigmoid(pred_out)\n",
    "        # Move predicted output and labels to CPU\n",
    "        pred_out = pred_out.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        #i+=1\n",
    "        # Store predictions and true labels\n",
    "        #print(i)\n",
    "        #print(outputs)\n",
    "        #print(logits)\n",
    "        #print(label_ids)\n",
    "    pred_outs.append(pred_out)\n",
    "    true_labels.append(label_ids)\n",
    "    \n",
    "# Combine the results across all batches. \n",
    "flat_pred_outs = np.concatenate(pred_outs, axis=0)\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "print(flat_pred_outs.shape , flat_true_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c626cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3.92310761e-06, 4.30220989e-03, 1.16946190e-02, 2.34892701e-01],\n",
       "        [8.64121955e-02, 1.16946190e-02, 1.95320027e-07, 6.38504560e-01],\n",
       "        [3.92310761e-06, 5.82240793e-04, 2.14194418e-04, 1.16946190e-02]]),\n",
       " array([2.71828183, 0.13533528, 0.04978707]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "(softmax([[-3,4,5,8],[7,5,-6,9],[-3,2,1,5]])), np.exp([1,-2,-3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27892f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "([[-3,4,5,8],[7,5,-6,9],[-3,2,1,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6f8ccd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.56365484e-05, 1.71475574e-02, 4.66118937e-02, 9.36224912e-01])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax([-3,4,5,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec1d0835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dac78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_exp = [[-0.2455, -0.1434, -0.0611,  0.2274, -0.1777, -0.4269,  0.0411],\n",
    "        [ 0.1890, -0.1654, -0.3152,  0.0682,  0.0319,  0.0546,  0.5577],\n",
    "        [-0.0895, -0.2367,  0.0864, -0.0883,  0.0559,  0.1175,  0.2676],\n",
    "        [ 0.1260, -0.0741, -0.1121,  0.2380, -0.0779,  0.0131,  0.1981],\n",
    "        [ 0.3605, -0.1398, -0.3145,  0.2203, -0.1846,  0.1293,  0.3266],\n",
    "        [-0.2461, -0.2586,  0.0239, -0.2525, -0.0506, -0.1413,  0.4473],\n",
    "        [-0.0562, -0.0878,  0.2782,  0.2046, -0.4587,  0.4339,  0.5150],\n",
    "        [-0.2414, -0.2358,  0.2084, -0.1253, -0.4013,  0.1053,  0.6817]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc032a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45d9493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[-3.6984,4.4987,5.9874645,8.6498],[7.2165,5.786,-6.648,9.38],[-3.19613,2.1597496,1.78564,5.34984]]\n",
    "linear_dd = nn.Linear(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4a5e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_ = linear_dd(torch.tensor(a), dim=1)\n",
    "thres_exp = 0.018\n",
    "softed = softmax(arr_exp)\n",
    "\n",
    "preds_exp = []\n",
    "for row in softed:\n",
    "    temp_exp = []\n",
    "    for val in row:\n",
    "        if(val > thres_exp):\n",
    "            temp_exp.append(1)\n",
    "        else:\n",
    "            temp_exp.append(0)\n",
    "    preds_exp.append(temp_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbe1f741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "447e4ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2 , 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 ,\n",
       "       0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41,\n",
       "       0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholdexp  = np.arange(0.2,0.51,0.01)\n",
    "thresholdexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "6a422e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold Value = 0.42000000000000004\n",
      "scores: \n",
      "[0.7362171331636981, 0.7377472055030095, 0.7383015597920277, 0.73665791776028, 0.7360988526037069, 0.7342222222222222, 0.7305282005371531, 0.7249774571686203, 0.7247956403269754, 0.7221206581352834, 0.7199265381083563]\n"
     ]
    }
   ],
   "source": [
    "#define candidate threshold values\n",
    "threshold  = np.arange(0.2,0.51,0.01)\n",
    "threshold\n",
    "# convert probabilities into 0 or 1 based on a threshold value\n",
    "def classify(pred_prob,thresh):\n",
    "    y_pred = []\n",
    "\n",
    "    for tag_label_row in pred_prob:\n",
    "        temp=[]\n",
    "        for tag_label in tag_label_row:\n",
    "            if tag_label >= thresh:\n",
    "                temp.append(1) # Infer tag value as 1 (present)\n",
    "            else:\n",
    "                temp.append(0) # Infer tag value as 0 (absent)\n",
    "        y_pred.append(temp)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "from sklearn import metrics\n",
    "scores=[] # Store the list of f1 scores for prediction on each threshold\n",
    "\n",
    "#convert labels to 1D array\n",
    "y_true = flat_true_labels.ravel() \n",
    "\n",
    "for thresh in threshold:\n",
    "    \n",
    "    #classes for each threshold\n",
    "    pred_bin_label = classify(flat_pred_outs,thresh) \n",
    "\n",
    "    #convert to 1D array\n",
    "    y_pred = np.array(pred_bin_label).ravel()\n",
    "\n",
    "    scores.append(metrics.f1_score(y_true,y_pred))\n",
    "    \n",
    "# find the optimal threshold\n",
    "opt_thresh = threshold[scores.index(max(scores))]\n",
    "print(f'Optimal Threshold Value = {opt_thresh}')\n",
    "\n",
    "print(f\"scores: \\n{scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9df0e6",
   "metadata": {},
   "source": [
    "# Performance Score Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "bf393365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions for optimal threshold\n",
    "y_pred_labels = classify(flat_pred_outs,opt_thresh)\n",
    "y_pred = np.array(y_pred_labels).ravel() # Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "fc83b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test[:10], flat_true_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "109b335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(array_2d):\n",
    "    array_2d_ = array_2d.copy()\n",
    "    for idx_2d , arr in enumerate(array_2d_):\n",
    "        for idx_, value in enumerate(arr):\n",
    "            \n",
    "            if value == 0:\n",
    "                array_2d_[idx_2d][idx_] = -1\n",
    "            if value == 1:\n",
    "                array_2d_[idx_2d][idx_] = labelname2index[label_pos[idx_]]\n",
    "    return array_2d_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5cbb25d9",
   "metadata": {},
   "source": [
    "### i manually creates this one by looking at the position of each label in y_pred_labels\n",
    "label_pos = [ \"BPH\", \"adenoma\", \"carcinoma\", \"colon\", \"inflammation\", \"prostate\", \"stomach\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c865954",
   "metadata": {},
   "source": [
    "index2labelname = {7:'colon',\n",
    "                   1:'prostate',\n",
    "                   2:'stomach',\n",
    "                   3:'inflammation',\n",
    "                   4:'carcinoma',\n",
    "                   5:'adenoma',\n",
    "                   6:'BPH'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "be66a32b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.94      0.94      2373\n",
      "           1       0.97      0.97      0.97       147\n",
      "           2       0.68      0.65      0.66        88\n",
      "           3       0.62      0.16      0.25        51\n",
      "           4       0.65      0.74      0.70       140\n",
      "           5       0.43      0.16      0.23        19\n",
      "           6       0.00      0.00      0.00        22\n",
      "           7       0.75      0.88      0.81       128\n",
      "\n",
      "    accuracy                           0.90      2968\n",
      "   macro avg       0.63      0.56      0.57      2968\n",
      "weighted avg       0.89      0.90      0.89      2968\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fb198/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/fb198/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/fb198/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "in_temp_true = flat_true_labels\n",
    "in_temp_pred = np.array(y_pred_labels)\n",
    "\n",
    "flat_true_labels_converted = convert_labels(in_temp_true)\n",
    "flat_pred_labels_converted = convert_labels(in_temp_pred)\n",
    "\n",
    "flat_true_labels_converted = flat_true_labels_converted.ravel()\n",
    "flat_pred_labels_converted = flat_pred_labels_converted.ravel()\n",
    "\n",
    "print(metrics.classification_report(flat_true_labels_converted, flat_pred_labels_converted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "aad1638b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94      2373\n",
      "           1       0.76      0.72      0.74       595\n",
      "\n",
      "    accuracy                           0.90      2968\n",
      "   macro avg       0.85      0.83      0.84      2968\n",
      "weighted avg       0.90      0.90      0.90      2968\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## print(y_true.shape, y_pred.shape)\n",
    "print(metrics.classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "66beee19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Actual Tags</th>\n",
       "      <th>Predicted Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. (Rechts Basis medial): 0,8cm lange Stanze ...</td>\n",
       "      <td>(carcinoma, prostate)</td>\n",
       "      <td>(carcinoma, prostate)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 (15 mm Polyp IC-Klappe): Ein 1,1 x 0,7 x 0,...</td>\n",
       "      <td>(carcinoma,)</td>\n",
       "      <td>(colon,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dysplasiefreie, leicht hyperplastische Dickda...</td>\n",
       "      <td>(colon,)</td>\n",
       "      <td>(colon,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-3 Regelrecht aufgebaute Duodenalschleimhaut...</td>\n",
       "      <td>(inflammation, stomach)</td>\n",
       "      <td>(stomach,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 (Dünndarmmetastase bei Mamma- und Sigma-Ca)...</td>\n",
       "      <td>(colon,)</td>\n",
       "      <td>(colon,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1. (Antrum): Fragmentiertes, zusammen 0,3 cm ...</td>\n",
       "      <td>(stomach,)</td>\n",
       "      <td>(inflammation, stomach)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>1 (Prostata): Ein 50 g schweres, 6,0 x 4,2 x ...</td>\n",
       "      <td>(carcinoma, prostate)</td>\n",
       "      <td>(carcinoma, prostate)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>: 1 (Prostata): Ein 5,8 x 4,9 x 4,8 cm messend...</td>\n",
       "      <td>(prostate,)</td>\n",
       "      <td>(carcinoma, prostate)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Nachbericht:  Immunhistochemisch zeigt sich nu...</td>\n",
       "      <td>(carcinoma, stomach)</td>\n",
       "      <td>(carcinoma,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>in 2 Gefäßen ca. 130 g, max. 0,7 cm große Res...</td>\n",
       "      <td>(prostate,)</td>\n",
       "      <td>(prostate,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Body  \\\n",
       "0     1. (Rechts Basis medial): 0,8cm lange Stanze ...   \n",
       "1     1 (15 mm Polyp IC-Klappe): Ein 1,1 x 0,7 x 0,...   \n",
       "2     Dysplasiefreie, leicht hyperplastische Dickda...   \n",
       "3     1-3 Regelrecht aufgebaute Duodenalschleimhaut...   \n",
       "4     1 (Dünndarmmetastase bei Mamma- und Sigma-Ca)...   \n",
       "..                                                 ...   \n",
       "419   1. (Antrum): Fragmentiertes, zusammen 0,3 cm ...   \n",
       "420   1 (Prostata): Ein 50 g schweres, 6,0 x 4,2 x ...   \n",
       "421  : 1 (Prostata): Ein 5,8 x 4,9 x 4,8 cm messend...   \n",
       "422  Nachbericht:  Immunhistochemisch zeigt sich nu...   \n",
       "423   in 2 Gefäßen ca. 130 g, max. 0,7 cm große Res...   \n",
       "\n",
       "                 Actual Tags           Predicted Tags  \n",
       "0      (carcinoma, prostate)    (carcinoma, prostate)  \n",
       "1               (carcinoma,)                 (colon,)  \n",
       "2                   (colon,)                 (colon,)  \n",
       "3    (inflammation, stomach)               (stomach,)  \n",
       "4                   (colon,)                 (colon,)  \n",
       "..                       ...                      ...  \n",
       "419               (stomach,)  (inflammation, stomach)  \n",
       "420    (carcinoma, prostate)    (carcinoma, prostate)  \n",
       "421              (prostate,)    (carcinoma, prostate)  \n",
       "422     (carcinoma, stomach)             (carcinoma,)  \n",
       "423              (prostate,)              (prostate,)  \n",
       "\n",
       "[424 rows x 3 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = binarizer.inverse_transform(np.array(y_pred_labels))\n",
    "y_act = binarizer.inverse_transform(flat_true_labels)\n",
    "\n",
    "df_pred_2 = pd.DataFrame({'Body':x_test,'Actual Tags':y_act,'Predicted Tags':y_pred})\n",
    "df_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "59aba59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'actual_tag = df_pred_2[\"Actual Tags\"].tolist()\\nactual_num = []\\nact_total = []\\nfor act in actual_tag:\\n    true_temp = []\\n    for _x in act:\\n        true_temp.append(labelname2index[_x])\\n        act_total.append(labelname2index[_x])\\n    actual_num.append(true_temp)\\n    \\npred_tag_ = df_pred_2[\"Predicted Tags\"].tolist()\\npred_num = []\\npred_total = []\\nfor pred_ in pred_tag_:\\n    pred_temp = []\\n    for _x in pred_:\\n        pred_temp.append(labelname2index[_x])\\n        pred_total.append(labelname2index[_x])\\n    pred_num.append(pred_temp)\\n\\ndf_pred_2[\\'true_ids\\'] = actual_num\\ndf_pred_2[\\'pred_ids\\'] = pred_num\\n'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## not really needed\n",
    "\"\"\"actual_tag = df_pred_2[\"Actual Tags\"].tolist()\n",
    "actual_num = []\n",
    "act_total = []\n",
    "for act in actual_tag:\n",
    "    true_temp = []\n",
    "    for _x in act:\n",
    "        true_temp.append(labelname2index[_x])\n",
    "        act_total.append(labelname2index[_x])\n",
    "    actual_num.append(true_temp)\n",
    "    \n",
    "pred_tag_ = df_pred_2[\"Predicted Tags\"].tolist()\n",
    "pred_num = []\n",
    "pred_total = []\n",
    "for pred_ in pred_tag_:\n",
    "    pred_temp = []\n",
    "    for _x in pred_:\n",
    "        pred_temp.append(labelname2index[_x])\n",
    "        pred_total.append(labelname2index[_x])\n",
    "    pred_num.append(pred_temp)\n",
    "\n",
    "df_pred_2['true_ids'] = actual_num\n",
    "df_pred_2['pred_ids'] = pred_num\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e899f9af",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1048cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(description):\n",
    "    text_enc = tokenizer.encode_plus(\n",
    "            description,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length= MAX_LEN,\n",
    "            padding = 'max_length',\n",
    "            return_token_type_ids= False,\n",
    "            return_attention_mask= True,\n",
    "            truncation=True,\n",
    "            return_tensors = 'pt'      \n",
    "    )\n",
    "    model.to('cpu')\n",
    "    outputs = model(text_enc['input_ids'], text_enc['attention_mask'])\n",
    "    pred_out = outputs[0].detach().numpy()\n",
    "    #print(f'Outputs = {outputs}')\n",
    "    #print(f'Type = {type(outputs)}')\n",
    "    #print(f'Pred Outputs = {pred_out}')\n",
    "    #print(f'Type = {type(pred_out)}')\n",
    "    #preds = np.round(pred_out)\n",
    "    #print(pred_out, opt_thresh)\n",
    "    preds = [(pred > opt_thresh) for pred in pred_out ]\n",
    "    #pred_list = [ round(pred) for pred in pred_logits ]\n",
    "    #print(preds)\n",
    "    preds = np.asarray(preds)\n",
    "    #print(f'Predictions = {preds}')\n",
    "    #print(f'Type = {type(preds)}')\n",
    "    #print(mlb.classes_)\n",
    "    new_preds = preds.reshape(1,-1).astype(int)\n",
    "    #print(new_preds)\n",
    "    #print(new_preds)\n",
    "    pred_tags = new_preds\n",
    "    #print(mlb.inverse_transform(np.array(new_preds)))\n",
    "    return pred_tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "11098cf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      " Fragmentiert vorliegende 0,5 cm große Probeentnahmen aus dem Antrum (1), Korpus Pseudopolyp (2). . Nachbericht:  Wieangekündigt, haben wir von Position 2 noch ergänzende Sonderfärbungen angefertigt (Gastrin, Chromogranin A und Synaptophysin). Hierbei zeigt sich eine lineare ECL-Zell-Hyperplasie. Die Biopsie negativ für Gastrin, passend zu einer Entnahme aus dem Corpusbereich, es bestätigt sich somit auch das Vorliegen einer Typ-A-Gastritis. Kein Anhalt für Malignität. .  1. Magenschleimhaut vom \n",
      "==========   ==========   ==========\n",
      "real label:  ['stomach', 'inflammation']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[('stomach',)]\n",
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      " 1 (rechts Basis medial): Eine maximal 1,3 cm lange Stanze. Einbettung in toto. 2 (rechts Basis lateral): Eine maximal 1 cm lange Stanze und ein Bröckel. Einbettung in toto. 3 (Rechtsmitte medial): Zwei 1,0-0,9 cm lange Stanzen. Einbettung in toto. 4 (Rechtsmitte lateral): Eine 1 cm lange Stanze und multiple Bröckel. Einbettung in toto. 5 (rechts Apex medial): Zwei 0,8-0,3 cm lange Stanzen. Einbettung in toto. 6 (rechts Apex lateral): Zwei 1,0-0,5 cm lange Stanzen. Einbettung in toto. 7 (links B \n",
      "==========   ==========   ==========\n",
      "real label:  ['prostate', 'carcinoma']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[('prostate',)]\n",
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      "Nachbericht:  Im nachträglich eingebetteten Fettgewebe zeigen sich 7 weitere bis 0,3 cm in Durchmesser große Lymphknoten, 3 davon mit bis 0,2 cm großen Infiltraten des oben beschriebenen Karzinoms, ohne extranodale Ausbreitung. Abschließende TNM-Klassifikation: G3 pT3, pN2(3/19), V1, Pn0, R0. Immunhistochemisch keine eindeutige Positivität für Her2-neu (Her2-neu Score: 0). .  Gastrektomiepräparat mit einem im Bereich der großen Kurvatur wachsenden maximal 3,5 cm in Durchmesser großen ulzerierten \n",
      "==========   ==========   ==========\n",
      "real label:  ['carcinoma']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[()]\n",
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      " jeweils 0,5 cm durchmessende Proben vom Darm (1 und 2). .  1, 2: Dickdarmschleimhaut mit einer geringgradigen chronischen unspezifischen Entzündung ohne intraepitheliale Lymphozytenvermehrung. Keine Kryptenabszesse. Keine Architekturstörung. Die Entzündung hat einen unspezifischen Charakter und lässt insbesondere an eine infektiöse Ätiologie denken. Hinweise für eine chronische entzündliche Darmerkrankung ergeben sich nicht. Kein Adenom- oder Karzinomwachstum.  \n",
      "==========   ==========   ==========\n",
      "real label:  ['colon', 'inflammation']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[('colon',)]\n",
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      " 1. Lymphknoten Milzhilus: Ein 1,6 x 1,3 x 0,5 cm messendes lipomatöses Weichgewebsexcisat. Auf der Schnittfläche zeigt sich muzinöses Gewebe, halbiert und Einbettung in toto. 2. Lymphknoten Trachealbifurkation: Ein 1,1 x 0,7 x 0,5 cm messendes Weichgewebsexcisat, halbiert, Einbettung in toto. 3. Ligamentum hepatoduodenale: Ein 3,1 x 1,5 x 0,5 cm messendes lipomatöses Weichgewebsexcisat. Einbettung in toto. 4. Resektat, Teil des Ösophagus, Magen, Milz: Ein Gastrektomiepräparat mit einem 6 cm anh \n",
      "==========   ==========   ==========\n",
      "real label:  ['colon', 'stomach']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[()]\n",
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      " 1-16: Prostatabiopsien mit Infiltration durch ein azinäres Adenokarzinom der Prostata in den u.g. Positionen. Nebenbefundlich fibromyomatöse Prostatahyperplasie mit herdförmiger chronischer Prostatitis. Position 1: Infiltratanteil: 40%, Gleason-Muster: 4(80%), 5(20%) Position 2: Infiltratanteil: 75%, Gleason-Muster: 4(60%), 3(40%) Position 4: Infiltratanteil: 60%, Gleason-Muster: 4(80%), 3(20%) Position 12: Infiltratanteil: 20%, Gleason-Muster: 4(100%) Position 13: Infiltratanteil: 80%, Gleason \n",
      "==========   ==========   ==========\n",
      "real label:  ['prostate', 'carcinoma']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[('carcinoma', 'prostate')]\n",
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      " 1 (Vollwandresektion): Ein flaches Schleimhaut-Weichgewebe mit den Ausmaßen 3,5 x 3 x 1 cm. Zirkulär wird die Absetzung schwarz getuscht und zur Tiefe gelb. Die Schleimhaut insgesamt rötlich verfärbt und auf einem maximal 1 cm messenden Areal ulzeriert imponierend. .1: Die eine Präparatekappe, darauf zugeschnitten. .2: Die gegenüberliegende Präparatekappe, darauf zugeschnitten. .3-5: Restpräparat in Querschnitten. .  1.1-2: Ödematöse Dickdarmwandanteile mit herdförmigen lymphofollikulärem Infil \n",
      "==========   ==========   ==========\n",
      "real label:  ['colon', 'inflammation', 'adenoma']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[('colon',)]\n",
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      " 1 (Colon sigmoideum, Bauchdecke, Blasendach + Teilstück Omentum): Ein 19 x 17 x 9,5 cm messendes Multiviszeralresektat mit einem im fixierten Zustand 17 cm langen und in der Zirkumferenz max. 6,8 cm messenden Darmteilstück sowie Blasenwandanteil von 6 x 4,9 x 2,5 cm sowie Weichgewebsanteil mit aufsitzender Hautspindel von 9 x 3,8 cm (Hautspindel). Zentral im Resektat befindet sich ein 6,2 x 6,0 x 5,8 cm großer, ulzerierender Tumor, der Anteile der Blasenwand einnimmt. Weiterhin befindet sich im \n",
      "==========   ==========   ==========\n",
      "real label:  ['colon', 'inflammation', 'carcinoma']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[('colon',)]\n",
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      " in multiplen spanartigen Fragmenten zusammengesetzt 84 Gramm schweres Prostataresektatmaterial. Repräsentatives Gewebe (Prostataresektate Thuliumlaser Probenbecher 2 Gewicht 84 gr.). 1.1-1.10: Wir erhielten in multiplen spanartigen Fragmenten zusammengesetzt 95 Gramm schweres Prostataresektatmaterial. Repräsentatives Gewebe (Prostataresektate Thulliumlaser/ Gewicht 95 gr Probenbecher 1). Laut klinischen Angaben: BPH; mpMRT-Prostata (15.08.2019): keine suspekte Läsion. Prostatavolumen 180ml Klin \n",
      "==========   ==========   ==========\n",
      "real label:  ['prostate']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[('prostate',)]\n",
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      " Prostataspäne mit Veränderungen einer myoglandulären Hyperplasie mit Drüsenektasien, Sekretretention und Sekretverkalkungen sowie mit fokaler Basalzellhyperplasie. Miterfasste Anteile der intraprostatischen Urethra histologisch unauffällig. Kein Anhalt für Malignität.  \n",
      "==========   ==========   ==========\n",
      "real label:  ['prostate']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[('prostate',)]\n",
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      " 1. Truncus coeliacus: Fragmentiertes, zusammengelegt max. 2,9 cm messendes, lipomatöses Weichgewebe mit abgrenzbaren Verdichtungsherden. 1.1.-1.3. Einbettung in toto. 2. Ligamentum hepatoduodenale: Fragmentiertes, zusammen max. 2,6 cm messendes, lipomatöses Weichgewebe mit abgrenzbaren Verdichtungsherden. Einbettung von drei freipärparierten Verdichtungsherden. 3. Arteria lienalis: Fragmentiertes, zusammengelegt max. 3,9 cm messendes, lipomatöses Weichgewebe mit einem abgrenzbaren Verdichtungsh \n",
      "==========   ==========   ==========\n",
      "real label:  ['stomach', 'carcinoma']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[()]\n",
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      " 1. Lipomatöses Gewebe vom Bereich Truncus coeliacus (laut klinischer Angabe mit 6 tumorfreien Lymphknoten. 2. Tumorfreies lipomatöses gefäßführendes Gewebe (Omentum majus). 3. Lipomatöses Gewebe vom Bereich Ligamentum hepatoduodenale (laut klinischer Angabe) mit 9 tumorfreien Lymphknoten. 4. Tumorfreie Gallenblase mit einer mäßiggradigen chronischen Cholecystitis mit Schleimhautatrophie und mäßiger entzündlicher Beteiligung des Ductus cysticus. 5. Gastrektomiepräparat mit einem maximal 5 cm in  \n",
      "==========   ==========   ==========\n",
      "real label:  ['stomach']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[()]\n",
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      "Nachbericht:  Auch im nachträglich eingebetteten Material zeigt sich myoglanduläre Hyperplasie sowie eine fokal betonte leichte chronische unspezifische Prostatitis. Miterfasstes Urothel dysplasiefrei. Auch hier kein Nachweiß eines Prostatakarzinoms. Kein Anhalt für Malignität. .  Prostataspäne mit Veränderungen einer myoglandulären Hyperplasie mit Drüsenektasien und Sekretretention. Kleinherdig Basalzellhyperplasie. Zur abschließenden Einordnung wird das Material noch weiter bearbeitet, hierzu  \n",
      "==========   ==========   ==========\n",
      "real label:  ['prostate']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[('prostate',)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      " als PE Magen zusammen max. 0,5 × 0,5 cm messende Gewebsfragmente. .  Histologisch Corpusschleimhaut mit leichtgradig chronischer, inaktiver Entzündung mit foveolärer Hyperplasie und netziger Stromafibrose. Keine Drüsenkörperatrophie. Kein H.p.-Nachweis in der mod. Giemsa-Färbung. Der Befund entspricht einer Typ C-Gastritis. Kein Anhalt für Malignität.  \n",
      "==========   ==========   ==========\n",
      "real label:  ['stomach']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[('stomach',)]\n",
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      " 1 (Descendens 5 mm großer Polyp): Fragmentierte, zusammen max. 0,4 cm durchmessende Schleimhautprobe. Einbettung in toto. 2 (Transversum,ca. 1 cm großer, gestielter Polyp): Eine 1 x 0,6 x 0,3 cm große, bräunliche, annähernd fingerförmige Schleimhautprobe. Die vermeintlich basale Resektionskante wird blau getuscht. Einbettung in Längsschnitten in toto. 3 (Rechte Flexur, ca. 2 cm großer, flacher Polyp): Fragmentierte, zusammen max. 1 cm durchmessende Schleimhautprobe. Einbettung in toto. .  1. Ei \n",
      "==========   ==========   ==========\n",
      "real label:  ['colon', 'adenoma']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[('colon',)]\n",
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      " 1 (Lymphknoten Arteria lienalis): Fragmentiertes, bräunliches, lipomatöses, zusammen 4 x 3 x 2,5 cm messendes Weichgewebe mit tastbaren Verdichtungsherden. Einbettungder Verdichtungsherde, wobei sich in 1.2 ein Konglomerat in toto befindet. 2 (Lymphknoten Arteria hepatica): Fragmentiertes, bräunliches, lipomatöses, zusammen 2 x 2 x 1,6 cm messendes Weichgewebe mit tastbaren Verdichtungsherden. Einbettung der Verdichtungsherde, wobei sich in 2.2 eine halbierte lymphknotenverdächtige Struktur bef \n",
      "==========   ==========   ==========\n",
      "real label:  ['stomach', 'carcinoma']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[()]\n",
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      "Nachbericht:  Wir haben noch weitere Färbungen unter Verwendung von Antikörper gegen Aktin, CD34 und D2-40 durchgeführt. Hierbei zeigt sich, daß Tumorausläufer zumindest bis in obere Anteile der Lamina submucosa hineinreichen. die gemessene tiefenausdehung beträgt 1,5 mm. Es ist entsprechend von einer pT1b (zumindest sm1)-Situation auszugehen. In der Färbung gegen D2-40 läßt sich eine Lymphangioinvasion erkennen. Es ist somit von einer Hochrisiko-Situation hinsichtlich eines positiven Nodalstatu \n",
      "==========   ==========   ==========\n",
      "real label:  ['stomach']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[()]\n",
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      " max. 0,4 cm große Gewebeproben von rechter Flexur (1), Sigma (2) und Rektum (3). Aufarbeitung in Stufen, HE. .  1. Ein tubuläres Adenom der Dickdarmschleimhaut mit einer niedriggradigen intraepithelialen Neoplasie (Kategorie 3 der mod. Wien-Klassifikation), das nach Präparatelage in toto reseziert wurde. 2. Regelrecht aufgebaute, tumor- und dysplasiefreie Kolonschleimhaut. 3. Ein hyperplastischer Polyp der Rektumschleimhaut. Kein Anhalt für Malignität.  \n",
      "==========   ==========   ==========\n",
      "real label:  ['colon', 'adenoma']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[('colon',)]\n",
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      " 1, 2: Antrum- bzw. Corpusschleimhaut mit einer mäßiggradigen chronischen und leichtgradig aktiven Pangastritis mit Nachweis von Helicobacter pylori (Typ B Gastritis). Zusätzlich eine kleinherdige incomplete intestinale Metaplasie. Der Drüsenkörper der Corpusschleimhaut unauffällig. 3: Duodenalschleimhaut mit einer leichtgradigen chronischen unspezifischen Duodenitis ohne intraepitheliale Lymphozytenvermehrung. Die Zottenarchitektur regelrecht. Histologisch kein Erregernachweis. 4: Anteile eines \n",
      "==========   ==========   ==========\n",
      "real label:  ['stomach', 'inflammation', 'adenoma']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[('stomach',)]\n",
      "========== Test Result ==========\n",
      "description: \n",
      "\n",
      " 1 (Omentum majus): Ein max.7,0 x 6,5 x 4,0 cm messendes, lipomatöses Weichgewebe. Auf der Schnittfläche durch das Präparat makroskopisch kein Herdbefund abgrenzbar. Einbettung eines Querschnitts. 2 (Gallenblase): Ein bereits eröffnetes, max. 6,6 x 2,6 x 1,8 cm messendes Cholezystektomiepräparat mit überwiegend samtartiger Schleimhaut, besetzt mit gelblichen Stippchen und kleineren Konkrementen. Einbettung der Absetzung im Tangentialschnitt und der Gallenblasenwand im Längsschnitt. 3 (Magen): Ei \n",
      "==========   ==========   ==========\n",
      "real label:  ['stomach']\n",
      "==========   ==========   ==========\n",
      "predicted labels: \n",
      "[('colon',)]\n"
     ]
    }
   ],
   "source": [
    "clinical_texts = df_mulitlabel.text.tolist()\n",
    "for i in range(0,20):#,500,1000,1520]:\n",
    "    tags = predict(clinical_texts[i])\n",
    "    print(\"========== Test Result ==========\")\n",
    "    print(\"description: \\n\")\n",
    "    print(clinical_texts[i][:500], \"\\n==========   ==========   ==========\")\n",
    "    print(\"real label: \", df_mulitlabel.iloc[i].label)\n",
    "    print(\"==========   ==========   ==========\")\n",
    "    print(\"predicted labels: \")\n",
    "    print(binarizer.inverse_transform(tags))\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "47d0147c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelsClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(1000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load a model along with its weights, biases and hyperparameters\n",
    "#m_name = \"dbmdz/bert-base-german-cased\"\n",
    "#n_c = 7\n",
    "#model = #LabelsClassifier(m_name, n_c)\n",
    "#model = LabelsClassifier.load_from_checkpoint(\"/home/fb198/BA/classification/multi_class/lightning_logs/version_7_sp_v1000/checkpoints/Labels-epoch=06-val_loss=0.25-train_loss=0.25.ckpt\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c604d",
   "metadata": {},
   "source": [
    "# del example BPH adenoma translate and original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "836b0e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-bcca669560a510d7\n",
      "Reusing dataset json (/home/fb198/.cache/huggingface/datasets/json/default-bcca669560a510d7/0.0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 1728\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "translated_text_path = \"/home/fb198/BA/DataNephroTexts/classification_data/disease/detsch_translated_data_disease_filtered.json\"\n",
    "dataset_translated = datasets.Dataset.from_json(translated_text_path)\n",
    "dataset_translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc3e7b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-95a779ba03b23aaa\n",
      "Reusing dataset json (/home/fb198/.cache/huggingface/datasets/json/default-95a779ba03b23aaa/0.0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 1779\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_text_path= \"/home/fb198/BA/DataNephroTexts/classification_data/data_files_classification_data_hf_dataset_disorder.json\"\n",
    "original_texts = datasets.Dataset.from_json(original_text_path)\n",
    "original_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "459a8103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3, 0], 3)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_texts['label'][78], dataset_translated['label'][53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "af9193db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 56, 73, 78, 139]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_bph_dx = [idx_ for idx_,val in enumerate(original_texts['label']) if val == 3]\n",
    "(original_bph_dx[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3f7f5b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e: 1. (Enukleationsgewebe, HOLEP Prostata): Fragmentiertes, insgesamt 75 g schweres Material. Einbettung in toto. Beurteilung: Fragmentiertes Prostataparenchym ohne Nachweis von Karzinominfiltraten, mit einer herdförmigen, teils follikelbildenden, lymphozytären chronischen, unspezifischen Entzündung. Miterfasstes Urothel der prostatischen Urehtra dysplasiefrei. Kein Anhalt für Malignitätim vorliegenden Material. Prof. Dr. me'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_texts['text'][56][54:-70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "08b6210a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(Enukleationsgewebe HOLEP Prostata): Fragmentiert insgesamt 75 g schweres Material. Einbetten in Toto. • Fragmentiertes Prostataparenchym ohne Nachweis von Karzinomfiltraten mit einer herdenförmigen teilweise follikelbildenden lymphatischen chronischen unspezifischen Entzündung. Das Prostataurehtra ist frei von Dysplasie. Kein Anhalt für Malignität im verfügbaren Material'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_translated['text'][53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cd9b4223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fragmentiertes, insgesamt 75 g schweres Material. Einbettung in toto. Beurteilung: Fragmentiertes Prostataparenchym ohne Nachweis von Karzinominfiltraten, mit einer herdförmigen, teils follikelbildenden, lymphozytären chronischen, unspezifischen Entzündung. Miterfasstes Urothel der prostatischen Urehtra dysplasiefrei.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Fragmentiertes, insgesamt 75 g schweres Material. Einbettung in toto. Beurteilung: Fragmentiertes Prostataparenchym ohne Nachweis von Karzinominfiltraten, mit einer herdförmigen, teils follikelbildenden, lymphozytären chronischen, unspezifischen Entzündung. Miterfasstes Urothel der prostatischen Urehtra dysplasiefrei.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "23194ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Fragmentiert insgesamt 75 g schweres Material. Einbetten in Toto. • Fragmentiertes Prostataparenchym ohne Nachweis von Karzinomfiltraten mit einer herdenförmigen teilweise follikelbildenden lymphatischen chronischen unspezifischen Entzündung. Das Prostataurehtra ist frei von Dysplasie.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" Fragmentiert insgesamt 75 g schweres Material. Einbetten in Toto. • Fragmentiertes Prostataparenchym ohne Nachweis von Karzinomfiltraten mit einer herdenförmigen teilweise follikelbildenden lymphatischen chronischen unspezifischen Entzündung. Das Prostataurehtra ist frei von Dysplasie.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c5c7bf5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_351926/2355735933.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
